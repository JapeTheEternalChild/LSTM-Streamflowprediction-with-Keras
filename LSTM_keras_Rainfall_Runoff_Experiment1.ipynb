{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_keras_Rainfall_Runoff_Experiment1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xreWcmRRb4sL"
      ],
      "authorship_tag": "ABX9TyM0NqKfwCcNd/SIAXelSzHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JapeTheEternalChild/LSTM-Streamflowprediction-with-Keras/blob/main/LSTM_keras_Rainfall_Runoff_Experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UMkoc204LZx"
      },
      "source": [
        "# Rainfall-runoff modelling using Long Short-Term Memory (LSTM) networks (Library:Keras)\n",
        "##Experiment 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnvbzluF4k_5"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgawZ5Gm5JdE"
      },
      "source": [
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbTCnx-J5HR7"
      },
      "source": [
        "# import libraries\n",
        "from pydrive.drive import GoogleDrive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "import os\n",
        "import glob\n",
        "# load keras and co\n",
        "import keras\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import CuDNNLSTM\n",
        "from keras import backend as K\n",
        "import torch\n",
        "# from sklearn\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FTFljv65fvD"
      },
      "source": [
        "## mount google drive & GPU connect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xDthHfa0tcn",
        "outputId": "8b21b2e3-68a9-4883-b3d8-c233efc663b2"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqhnL1e15Yxg",
        "outputId": "8412336f-22e7-4357-ec50-5e2f332245f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX_kePZd4lf7"
      },
      "source": [
        "## 1. Define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTfQBT7O4mt2"
      },
      "source": [
        "# Import & Preprocess Data Function\n",
        "\n",
        "def read_data(filename_daymet, filename_flow):\n",
        "  # daily metereo mean data\n",
        "  daymet = pd.read_csv(filename_daymet, sep='\\t', header=4)\n",
        "  daymet.columns =['Datetime', 'dayl(s)', 'prcp(mm/d)', 'srad(W/m2)', 'swe(mm)', 'tmax(c)', 'tmin(C)', 'vp(Pa)']  # name columns\n",
        "  # get catchment area\n",
        "  with open(filename_daymet, 'r') as fp:\n",
        "      content = fp.readlines()\n",
        "      area = int(content[2])\n",
        "  # daily streamflow data\n",
        "  flow = pd.read_csv(filename_flow, header=None, delim_whitespace=True)\n",
        "  flow = flow[4] # select column\n",
        "  flow = flow[1:] # drop first line 1.1.1980 because daymet starts from the 2.1.1980\n",
        "  flow.reset_index(drop=True, inplace=True) # reset index\n",
        "  flow = 28316846.592 * flow * 86400 / (area * 10 ** 6) # from cubic feet per second to equivalent water column in mm\n",
        "  # combine daymet and streamflow\n",
        "  data = pd.concat([daymet, flow], axis=1)\n",
        "  data['Datetime'] =  pd.to_datetime(data['Datetime'], format='%Y %m %d %H')  # set Datetime format\n",
        "  data['Datetime'] = pd.to_datetime(data['Datetime']).dt.date # drop hours\n",
        "  data = data.set_index(pd.DatetimeIndex(data['Datetime']))\n",
        "  data = data.drop(['swe(mm)'], axis=1)\n",
        "  data = data.drop(['Datetime'], axis=1)\n",
        "  data = data.drop(['dayl(s)'], axis=1)\n",
        "  data_old = data.shape[0]\n",
        "  # delete missing data\n",
        "  \n",
        "  data.columns =['prcp(mm/d)', 'srad(W/m2)', 'tmax(c)', 'tmin(C)', 'vp(Pa)', 'Q_spec(mm)']  # name columns\n",
        "  idxNegatives = data[data['Q_spec(mm)'] < 0].index \n",
        "  data.drop(idxNegatives, inplace = True)\n",
        "  data.dropna(inplace = True)\n",
        "  # Print how many samples where deleted\n",
        "  deleted = data_old-data.shape[0]\n",
        "  print( deleted, 'SAMPLES WHERE DELETED DUE TO MISSING DATA')\n",
        "\n",
        "  return data\n",
        "\n",
        "# split data\n",
        "\n",
        "def split_data1(data):\n",
        "  df_train = data['1980-10-01':'1995-09-30']\n",
        "  df_test = data['1995-10-01':'2010-09-30']\n",
        "  return df_train, df_test\n",
        "\n",
        "# Z-Standartization --> scaling of data (mean=0, standard deviation = 1)\n",
        "\n",
        "def local_standartization(data):\n",
        "  stds = data.std()\n",
        "  mean = data.mean()\n",
        "  scaled_data = (data-mean)/stds\n",
        "  return scaled_data, stds, mean\n",
        "\n",
        "def scale(data, stds, mean):\n",
        "  scaled_data = (data-mean)/stds\n",
        "  return scaled_data\n",
        "\n",
        "# Rescaling discharge values \n",
        "\n",
        "def rescale(data_discharge, stds, mean):\n",
        "  y_stds = stds.loc['Q_spec(mm)']\n",
        "  y_mean = mean.loc['Q_spec(mm)']\n",
        "  rescaled_discharge = (data_discharge * y_stds) +  y_mean\n",
        "  return rescaled_discharge\n",
        "\n",
        "# shift timeseries for t days\n",
        "\n",
        "def shift(data, t):\n",
        "  data_to_shift = data.drop(['Q_spec(mm)'], axis = 1)\n",
        "  Q = data['Q_spec(mm)']\n",
        "  lags= range(0,t)\n",
        "  data_shifted = pd.concat([data_to_shift.shift(t).add_suffix(f\" (t-{t})\") for t in lags], axis=1)\n",
        "  data_shifted = pd.concat([data_shifted, Q], axis = 1)\n",
        "  return data_shifted\n",
        "\n",
        "# split dataframe into train and test data; define input(x) and control(y) values; reshape input df from 2D to 3D\n",
        "\n",
        "def split_data(train_shifted, test_shifted):\n",
        "  #df_train = train_shifted['1980-10-01':'1995-09-30']\n",
        "  #df_test = test_shifted['1995-10-01':'2010-09-30']\n",
        "  y_train = train_shifted['Q_spec(mm)'].values\n",
        "  x_train = train_shifted.loc[:, train_shifted.columns != 'Q_spec(mm)'].values\n",
        "  y_test = test_shifted['Q_spec(mm)'].values\n",
        "  x_test = test_shifted.loc[:, test_shifted.columns != 'Q_spec(mm)'].values\n",
        "  #x_train = np.expand_dims(x_train,2)\n",
        "  #x_test = np.expand_dims(x_test, 2)\n",
        "  return y_train, x_train, y_test, x_test\n",
        "\n",
        "#NSE function\n",
        "def get_nse(y_test, predictions):\n",
        "  numerator = sum([(y_test[i]-predictions[i])**2 for i in range(len(y_test))])\n",
        "  y_test_avg = sum(y_test)/len(y_test)\n",
        "  denominator = sum([(y_test[i]-y_test_avg)**2 for i in range(len(y_test))])\n",
        "  NSE = 1- (numerator/denominator)\n",
        "  return NSE\n",
        "\n",
        "def calc_nse(obs: np.array, sim: np.array) -> float:\n",
        "    \"\"\"Calculate Nash-Sutcliff-Efficiency.\n",
        "\n",
        "    :param obs: Array containing the observations\n",
        "    :param sim: Array containing the simulations\n",
        "    :return: NSE value.\n",
        "    \"\"\"\n",
        "    # only consider time steps, where observations are available\n",
        "    sim = np.delete(sim, np.argwhere(obs < 0), axis=0)\n",
        "    obs = np.delete(obs, np.argwhere(obs < 0), axis=0)\n",
        "\n",
        "    # check for NaNs in observations\n",
        "    sim = np.delete(sim, np.argwhere(np.isnan(obs)), axis=0)\n",
        "    obs = np.delete(obs, np.argwhere(np.isnan(obs)), axis=0)\n",
        "\n",
        "    denominator = np.sum((obs - np.mean(obs)) ** 2)\n",
        "    numerator = np.sum((sim - obs) ** 2)\n",
        "    nse_val = 1 - numerator / denominator\n",
        "\n",
        "    return nse_val\n",
        "\n",
        "#using NSE as metrics function\n",
        "def metrics_nse(y_obs,y_sim):\n",
        "  numerator = K.sum(K.square(y_sim - y_obs))\n",
        "  denominator = K.sum(K.square(y_obs - K.mean(y_obs)))\n",
        "  return 1-(numerator/denominator)\n",
        "\n",
        "#using NSE as loss function\n",
        "def loss_NSE(y_obs, y_sim):\n",
        "  numerator = K.sum(K.square(y_sim - y_obs))\n",
        "  denominator = K.sum(K.square(y_obs - K.mean(y_obs)))\n",
        "  return numerator/denominator\n",
        "\n",
        "#LSTM\n",
        "\n",
        "def model_lstm(x_train, loss, metrics):\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(20, input_shape=x_train.shape[1:], return_sequences = True, activation = \"tanh\"))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(LSTM(20, activation = \"tanh\"))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss=loss, optimizer='adam', metrics=metrics)\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model\n",
        "\n",
        "# optimizer\n",
        "\n",
        "\n",
        "\n",
        "# GRU\n",
        "''' gated recurrent unit after Cho, et al. in 2014\n",
        "using a keras based sequencial model '''\n",
        "\n",
        "def model_gru(x_train, loss, metrics):\n",
        "  model = Sequential()\n",
        "  model.add(GRU(20, activation=\"tanh\", input_shape=x_train.shape[1:], use_bias=True, return_sequences = True, recurrent_activation=\"sigmoid\"))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(GRU(20, activation=\"tanh\", use_bias=True, recurrent_activation=\"sigmoid\"))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
        "\n",
        "  print(model.summary())\n",
        "\n",
        "  return model\n",
        "\n",
        "# Train the Model\n",
        "\n",
        "def train(model, x_train, y_train, epochs, batch_size):\n",
        " history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=False)\n",
        " return history\n",
        "\n",
        " # Evaluate model\n",
        "\n",
        "def get_accuracy(model,x,y):\n",
        " loss = model.evaluate(x, y)\n",
        " return loss\n",
        "\n",
        "# Validation\n",
        "\n",
        "def prediction(model, x_test):\n",
        "  predictions = model.predict(x_test)\n",
        "  return predictions\n",
        "\n",
        "def lstm_data_transform(x_data, y_data, num_steps=5):\n",
        "    \"\"\" Changes data to the format for LSTM training \n",
        "for sliding window approach \"\"\"\n",
        "# Prepare the list for the transformed data\n",
        "    X, y = list(), list()\n",
        "# Loop of the entire data set\n",
        "    for i in range(x_data.shape[0]):\n",
        "        # compute a new (sliding window) index\n",
        "        end_ix = i + num_steps\n",
        "# if index is larger than the size of the dataset, we stop\n",
        "        if end_ix >= x_data.shape[0]:\n",
        "            break\n",
        "# Get a sequence of data for x\n",
        "        seq_X = x_data[i:end_ix]\n",
        "        # Get only the last element of the sequency for y\n",
        "        seq_y = y_data[end_ix]\n",
        "# Append the list with sequencies\n",
        "        X.append(seq_X)\n",
        "        y.append(seq_y)\n",
        "# Make final arrays\n",
        "    x_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "    return x_array, y_array\n",
        "\n",
        "\n",
        "# Callbacks\n",
        "\n",
        "class CustomCallback(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    y_pred = self.model.predict(self.validation_data[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xreWcmRRb4sL"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDtpehs3u55G"
      },
      "source": [
        "If validation loss >> training loss you can call it overfitting.\n",
        "\n",
        "If validation loss  > training loss you can call it some overfitting.\n",
        "\n",
        "If validation loss  < training loss you can call it some underfitting.\n",
        "\n",
        "If validation loss << training loss you can call it underfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtIyyTHZkSPn"
      },
      "source": [
        "#make prediction\n",
        "predictions= prediction(model, x_test_transformed)\n",
        "training_pred = prediction(model, x_train_transformed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "ODE3LETdmM9j",
        "outputId": "eb9088b9-f23d-4cbf-e004-9510741ffc4b"
      },
      "source": [
        "#print predicitons \n",
        "pred_rescaled = rescale(predictions, test_mean, test_std)\n",
        "df_test_new = data['1996-09-30':'2010-09-30']\n",
        "# plot example\n",
        "fig=plt.figure(figsize=(7, 5), dpi= 150, facecolor='w', edgecolor='k')\n",
        "plt.plot(df_test_new.index, df_test_new['Q_spec(mm)'])\n",
        "plt.ylabel('discharge Q[m3/s]')\n",
        "plt.plot(df_test_new.index, pred_rescaled.flatten(), alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1050x750 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#plt.plot(pred_rescaled)\n",
        "plt.plot(df_test_new['Q_spec(mm)'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "FNcIHX4noDNk",
        "outputId": "625d308c-e5cf-4000-bd30-c7f53e15df7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f94d04c31d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "NwUShAIPyg2m",
        "outputId": "10bbcbe6-2dc4-4fa8-9dde-c2706997cbaa"
      },
      "source": [
        "\n",
        "\n",
        "nse_val = get_nse(data['Q_spec(mm)']['1996-09-30':'2010-09-29'].values, pd.Series(pred_rescaled.flatten).values)\n",
        "\n",
        "print(nse_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-99-5a26c3de26ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnse_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_nse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Q_spec(mm)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1996-09-30'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'2010-09-29'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_rescaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnse_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-60da98cc9a73>\u001b[0m in \u001b[0;36mget_nse\u001b[0;34m(y_test, predictions)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m#NSE function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_nse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0my_test_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_test_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-60da98cc9a73>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m#NSE function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_nse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m   \u001b[0mnumerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m   \u001b[0my_test_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m   \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_test_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'builtin_function_or_method'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lala = pd.Series(pred_rescaled.flatten(), index=df_test_new['Q_spec(mm)'].index)"
      ],
      "metadata": {
        "id": "nQsZ7ZVorsPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nse_val = get_nse(df_test_new['Q_spec(mm)']['1997-09-30':'2010-09-30'], lala['1997-09-1':'2010-09-29'])\n",
        "\n",
        "print(nse_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAcqtpjTsAes",
        "outputId": "d1f69b4c-cf42-4f6f-9065-020e9abbfec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.34880611295422925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nse(obs, sim):\n",
        "  obs_mean = np.mean(obs)\n",
        "  nse = 1-np.mean((obs - sim)**2)/(np.mean((obs - obs_mean)**2))\n",
        "  return(nse)"
      ],
      "metadata": {
        "id": "_lyM9LAYscPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = df_test_new['Q_spec(mm)']['1996-09-30':'2010-09-29']\n",
        "sim = lala['1996-10-01':'2010-09-30']"
      ],
      "metadata": {
        "id": "quRtmou1tIca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nse(obs.values, sim.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5LhVvMCs2Yi",
        "outputId": "584f8c03-d836-4f8d-91f6-4443d18168bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1763.0272497955402"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_new['Q_spec(mm)']['1997-09-30':'2010-09-30']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMct4FplsYyC",
        "outputId": "0411e9fe-721a-4140-f807-16dff8234359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datetime\n",
              "1997-09-30    0.134748\n",
              "1997-10-01    0.132951\n",
              "1997-10-02    0.125765\n",
              "1997-10-03    0.123968\n",
              "1997-10-04    0.122171\n",
              "                ...   \n",
              "2010-09-26    0.122171\n",
              "2010-09-27    0.118578\n",
              "2010-09-28    0.116782\n",
              "2010-09-29    0.116782\n",
              "2010-09-30    0.116782\n",
              "Name: Q_spec(mm), Length: 4749, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST new"
      ],
      "metadata": {
        "id": "U9a-FrZ75h9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huc = '03'\n",
        "basin_ID = '02395120'\n",
        "filename_daymet ='/content/drive/My Drive/Colab Notebooks/basin_mean_forcing/daymet/'+huc+'/'+basin_ID+'_lump_cida_forcing_leap.txt'\n",
        "filename_flow   ='/content/drive/My Drive/Colab Notebooks/usgs_streamflow/'+huc+'/'+basin_ID+'_streamflow_qc.txt'\n",
        "data = read_data(filename_daymet, filename_flow)\n",
        "\n",
        "df_train, df_test = split_data1(data)\n",
        "scaled_train, train_std, train_mean = local_standartization(df_train)\n",
        "scaled_test = scale(df_test, train_std, train_mean)\n",
        "y_train_sc, x_train_sc, y_test_sc, x_test_sc = split_data(scaled_train, scaled_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGh1BwY55mNb",
        "outputId": "ffce0de0-afce-4b60-b90e-6c755d044b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151 SAMPLES WHERE DELETED DUE TO MISSING DATA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "iVGmeZTH8r0Q",
        "outputId": "9050290f-aa1b-4d3b-fd2e-5c2d9c2bc28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-14827550-3a74-4a37-afb6-2200ed791510\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prcp(mm/d)</th>\n",
              "      <th>srad(W/m2)</th>\n",
              "      <th>tmax(c)</th>\n",
              "      <th>tmin(C)</th>\n",
              "      <th>vp(Pa)</th>\n",
              "      <th>Q_spec(mm)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1980-10-01</th>\n",
              "      <td>6.79</td>\n",
              "      <td>165.57</td>\n",
              "      <td>20.96</td>\n",
              "      <td>14.29</td>\n",
              "      <td>1622.89</td>\n",
              "      <td>0.314059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980-10-02</th>\n",
              "      <td>0.00</td>\n",
              "      <td>325.26</td>\n",
              "      <td>24.30</td>\n",
              "      <td>13.64</td>\n",
              "      <td>1571.35</td>\n",
              "      <td>0.314059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980-10-03</th>\n",
              "      <td>0.00</td>\n",
              "      <td>423.99</td>\n",
              "      <td>23.97</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1080.00</td>\n",
              "      <td>1.199134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980-10-04</th>\n",
              "      <td>0.00</td>\n",
              "      <td>425.22</td>\n",
              "      <td>20.03</td>\n",
              "      <td>4.34</td>\n",
              "      <td>827.22</td>\n",
              "      <td>0.685220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1980-10-05</th>\n",
              "      <td>0.00</td>\n",
              "      <td>360.05</td>\n",
              "      <td>18.23</td>\n",
              "      <td>6.37</td>\n",
              "      <td>950.15</td>\n",
              "      <td>0.599567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-09-26</th>\n",
              "      <td>1.00</td>\n",
              "      <td>265.46</td>\n",
              "      <td>21.09</td>\n",
              "      <td>14.34</td>\n",
              "      <td>1627.03</td>\n",
              "      <td>11.563081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-09-27</th>\n",
              "      <td>0.00</td>\n",
              "      <td>396.24</td>\n",
              "      <td>23.99</td>\n",
              "      <td>12.32</td>\n",
              "      <td>1425.85</td>\n",
              "      <td>52.533504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-09-28</th>\n",
              "      <td>0.00</td>\n",
              "      <td>417.50</td>\n",
              "      <td>25.01</td>\n",
              "      <td>11.91</td>\n",
              "      <td>1392.66</td>\n",
              "      <td>7.508865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-09-29</th>\n",
              "      <td>0.00</td>\n",
              "      <td>423.36</td>\n",
              "      <td>25.36</td>\n",
              "      <td>11.75</td>\n",
              "      <td>1379.98</td>\n",
              "      <td>4.368275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995-09-30</th>\n",
              "      <td>0.00</td>\n",
              "      <td>404.35</td>\n",
              "      <td>25.45</td>\n",
              "      <td>12.74</td>\n",
              "      <td>1459.30</td>\n",
              "      <td>3.825810</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5478 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14827550-3a74-4a37-afb6-2200ed791510')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-14827550-3a74-4a37-afb6-2200ed791510 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-14827550-3a74-4a37-afb6-2200ed791510');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            prcp(mm/d)  srad(W/m2)  tmax(c)  tmin(C)   vp(Pa)  Q_spec(mm)\n",
              "Datetime                                                                 \n",
              "1980-10-01        6.79      165.57    20.96    14.29  1622.89    0.314059\n",
              "1980-10-02        0.00      325.26    24.30    13.64  1571.35    0.314059\n",
              "1980-10-03        0.00      423.99    23.97     8.00  1080.00    1.199134\n",
              "1980-10-04        0.00      425.22    20.03     4.34   827.22    0.685220\n",
              "1980-10-05        0.00      360.05    18.23     6.37   950.15    0.599567\n",
              "...                ...         ...      ...      ...      ...         ...\n",
              "1995-09-26        1.00      265.46    21.09    14.34  1627.03   11.563081\n",
              "1995-09-27        0.00      396.24    23.99    12.32  1425.85   52.533504\n",
              "1995-09-28        0.00      417.50    25.01    11.91  1392.66    7.508865\n",
              "1995-09-29        0.00      423.36    25.36    11.75  1379.98    4.368275\n",
              "1995-09-30        0.00      404.35    25.45    12.74  1459.30    3.825810\n",
              "\n",
              "[5478 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_steps = 30\n",
        "# training set\n",
        "(x_train_transformed,\n",
        "y_train_transformed) = lstm_data_transform(x_train_sc, y_train_sc, num_steps=num_steps)\n",
        "assert x_train_transformed.shape[0] == y_train_transformed.shape[0]\n",
        "# test set\n",
        "(x_test_transformed,\n",
        "y_test_transformed) = lstm_data_transform(x_test_sc, y_test_sc, num_steps=num_steps)\n",
        "assert x_test_transformed.shape[0] == y_test_transformed.shape[0]"
      ],
      "metadata": {
        "id": "U1TrD-YU8xq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_transformed.shape[0]-df_test.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHKVm1Cx9GLV",
        "outputId": "070a43d6-7fec-4e50-f770-b0e42309127d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-365"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = 'mse'\n",
        "epochs=500\n",
        "batch_size = 512\n",
        "\n",
        "\n",
        "model = model_lstm(x_train_transformed, loss, metrics=metrics_nse)\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "model.fit(x_train_transformed, y_train_transformed, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3T2FU0BL9cay",
        "outputId": "7cd62cdb-7151-4a1b-9b9b-7e48d71afdf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 30, 20)            2080      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 30, 20)            0         \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 20)                3280      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 20)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,381\n",
            "Trainable params: 5,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/500\n",
            "11/11 [==============================] - 3s 7ms/step - loss: 0.9947 - metrics_nse: 0.0098\n",
            "Epoch 2/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9767 - metrics_nse: 0.0360\n",
            "Epoch 3/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9678 - metrics_nse: 0.0411\n",
            "Epoch 4/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9669 - metrics_nse: 0.0410\n",
            "Epoch 5/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9614 - metrics_nse: 0.0437\n",
            "Epoch 6/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9565 - metrics_nse: 0.0555\n",
            "Epoch 7/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9542 - metrics_nse: 0.0597\n",
            "Epoch 8/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9532 - metrics_nse: 0.0560\n",
            "Epoch 9/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9493 - metrics_nse: 0.0551\n",
            "Epoch 10/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9440 - metrics_nse: 0.0703\n",
            "Epoch 11/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9414 - metrics_nse: 0.0709\n",
            "Epoch 12/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.9387 - metrics_nse: 0.0708\n",
            "Epoch 13/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9346 - metrics_nse: 0.0728\n",
            "Epoch 14/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9328 - metrics_nse: 0.0798\n",
            "Epoch 15/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9273 - metrics_nse: 0.0809\n",
            "Epoch 16/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9178 - metrics_nse: 0.0941\n",
            "Epoch 17/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9140 - metrics_nse: 0.0957\n",
            "Epoch 18/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9063 - metrics_nse: 0.1063\n",
            "Epoch 19/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9079 - metrics_nse: 0.0946\n",
            "Epoch 20/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9051 - metrics_nse: 0.1085\n",
            "Epoch 21/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8985 - metrics_nse: 0.1061\n",
            "Epoch 22/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9045 - metrics_nse: 0.1048\n",
            "Epoch 23/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8908 - metrics_nse: 0.1257\n",
            "Epoch 24/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8873 - metrics_nse: 0.1231\n",
            "Epoch 25/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8889 - metrics_nse: 0.1245\n",
            "Epoch 26/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8929 - metrics_nse: 0.1139\n",
            "Epoch 27/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8846 - metrics_nse: 0.1250\n",
            "Epoch 28/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8726 - metrics_nse: 0.1314\n",
            "Epoch 29/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8728 - metrics_nse: 0.1288\n",
            "Epoch 30/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8783 - metrics_nse: 0.1245\n",
            "Epoch 31/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8684 - metrics_nse: 0.1369\n",
            "Epoch 32/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8729 - metrics_nse: 0.1278\n",
            "Epoch 33/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8739 - metrics_nse: 0.1431\n",
            "Epoch 34/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8738 - metrics_nse: 0.1336\n",
            "Epoch 35/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8619 - metrics_nse: 0.1468\n",
            "Epoch 36/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8604 - metrics_nse: 0.1523\n",
            "Epoch 37/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8690 - metrics_nse: 0.1207\n",
            "Epoch 38/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8624 - metrics_nse: 0.1420\n",
            "Epoch 39/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8532 - metrics_nse: 0.1483\n",
            "Epoch 40/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8589 - metrics_nse: 0.1538\n",
            "Epoch 41/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8399 - metrics_nse: 0.1765\n",
            "Epoch 42/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8501 - metrics_nse: 0.1647\n",
            "Epoch 43/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8506 - metrics_nse: 0.1470\n",
            "Epoch 44/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8578 - metrics_nse: 0.1356\n",
            "Epoch 45/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8538 - metrics_nse: 0.1574\n",
            "Epoch 46/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8366 - metrics_nse: 0.1784\n",
            "Epoch 47/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8418 - metrics_nse: 0.1614\n",
            "Epoch 48/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8200 - metrics_nse: 0.1769\n",
            "Epoch 49/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8259 - metrics_nse: 0.1834\n",
            "Epoch 50/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8076 - metrics_nse: 0.1861\n",
            "Epoch 51/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8118 - metrics_nse: 0.1887\n",
            "Epoch 52/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8225 - metrics_nse: 0.1778\n",
            "Epoch 53/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8108 - metrics_nse: 0.2048\n",
            "Epoch 54/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8080 - metrics_nse: 0.1915\n",
            "Epoch 55/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7985 - metrics_nse: 0.2127\n",
            "Epoch 56/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8058 - metrics_nse: 0.1829\n",
            "Epoch 57/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7907 - metrics_nse: 0.2180\n",
            "Epoch 58/500\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.7784 - metrics_nse: 0.2164\n",
            "Epoch 59/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7944 - metrics_nse: 0.2108\n",
            "Epoch 60/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8041 - metrics_nse: 0.1861\n",
            "Epoch 61/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7820 - metrics_nse: 0.2028\n",
            "Epoch 62/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7865 - metrics_nse: 0.1990\n",
            "Epoch 63/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7645 - metrics_nse: 0.2341\n",
            "Epoch 64/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7812 - metrics_nse: 0.2104\n",
            "Epoch 65/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7739 - metrics_nse: 0.2251\n",
            "Epoch 66/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7586 - metrics_nse: 0.2188\n",
            "Epoch 67/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7649 - metrics_nse: 0.2368\n",
            "Epoch 68/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7759 - metrics_nse: 0.2236\n",
            "Epoch 69/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7601 - metrics_nse: 0.2565\n",
            "Epoch 70/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7491 - metrics_nse: 0.2449\n",
            "Epoch 71/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7510 - metrics_nse: 0.2115\n",
            "Epoch 72/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7645 - metrics_nse: 0.2260\n",
            "Epoch 73/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7426 - metrics_nse: 0.2356\n",
            "Epoch 74/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7458 - metrics_nse: 0.2156\n",
            "Epoch 75/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7555 - metrics_nse: 0.2358\n",
            "Epoch 76/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7414 - metrics_nse: 0.2457\n",
            "Epoch 77/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7860 - metrics_nse: 0.1997\n",
            "Epoch 78/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7494 - metrics_nse: 0.2442\n",
            "Epoch 79/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7324 - metrics_nse: 0.2384\n",
            "Epoch 80/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7201 - metrics_nse: 0.2703\n",
            "Epoch 81/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7375 - metrics_nse: 0.2199\n",
            "Epoch 82/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7228 - metrics_nse: 0.2776\n",
            "Epoch 83/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7175 - metrics_nse: 0.2824\n",
            "Epoch 84/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7405 - metrics_nse: 0.2391\n",
            "Epoch 85/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7122 - metrics_nse: 0.2784\n",
            "Epoch 86/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7218 - metrics_nse: 0.2832\n",
            "Epoch 87/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7268 - metrics_nse: 0.2589\n",
            "Epoch 88/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7064 - metrics_nse: 0.2969\n",
            "Epoch 89/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7201 - metrics_nse: 0.2589\n",
            "Epoch 90/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7239 - metrics_nse: 0.2665\n",
            "Epoch 91/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7149 - metrics_nse: 0.2660\n",
            "Epoch 92/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7101 - metrics_nse: 0.2931\n",
            "Epoch 93/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7112 - metrics_nse: 0.2933\n",
            "Epoch 94/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7255 - metrics_nse: 0.2820\n",
            "Epoch 95/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7169 - metrics_nse: 0.2826\n",
            "Epoch 96/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7112 - metrics_nse: 0.2682\n",
            "Epoch 97/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6962 - metrics_nse: 0.2716\n",
            "Epoch 98/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7106 - metrics_nse: 0.2727\n",
            "Epoch 99/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6941 - metrics_nse: 0.3192\n",
            "Epoch 100/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6991 - metrics_nse: 0.2859\n",
            "Epoch 101/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.7040 - metrics_nse: 0.3023\n",
            "Epoch 102/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6889 - metrics_nse: 0.2931\n",
            "Epoch 103/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6793 - metrics_nse: 0.2871\n",
            "Epoch 104/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6874 - metrics_nse: 0.3059\n",
            "Epoch 105/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6921 - metrics_nse: 0.3021\n",
            "Epoch 106/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6945 - metrics_nse: 0.2885\n",
            "Epoch 107/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6981 - metrics_nse: 0.2940\n",
            "Epoch 108/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6892 - metrics_nse: 0.3034\n",
            "Epoch 109/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6723 - metrics_nse: 0.2864\n",
            "Epoch 110/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6552 - metrics_nse: 0.3216\n",
            "Epoch 111/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6669 - metrics_nse: 0.2985\n",
            "Epoch 112/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6784 - metrics_nse: 0.3280\n",
            "Epoch 113/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6559 - metrics_nse: 0.3387\n",
            "Epoch 114/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6596 - metrics_nse: 0.3204\n",
            "Epoch 115/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6739 - metrics_nse: 0.2881\n",
            "Epoch 116/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6665 - metrics_nse: 0.2885\n",
            "Epoch 117/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6632 - metrics_nse: 0.3259\n",
            "Epoch 118/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6645 - metrics_nse: 0.3003\n",
            "Epoch 119/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6650 - metrics_nse: 0.2843\n",
            "Epoch 120/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6629 - metrics_nse: 0.3009\n",
            "Epoch 121/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6658 - metrics_nse: 0.3208\n",
            "Epoch 122/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6482 - metrics_nse: 0.3215\n",
            "Epoch 123/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6219 - metrics_nse: 0.3497\n",
            "Epoch 124/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6401 - metrics_nse: 0.3440\n",
            "Epoch 125/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6352 - metrics_nse: 0.3442\n",
            "Epoch 126/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6396 - metrics_nse: 0.3420\n",
            "Epoch 127/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6349 - metrics_nse: 0.3353\n",
            "Epoch 128/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6433 - metrics_nse: 0.3509\n",
            "Epoch 129/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6422 - metrics_nse: 0.3846\n",
            "Epoch 130/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6356 - metrics_nse: 0.3149\n",
            "Epoch 131/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6295 - metrics_nse: 0.3797\n",
            "Epoch 132/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6357 - metrics_nse: 0.3437\n",
            "Epoch 133/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6585 - metrics_nse: 0.3025\n",
            "Epoch 134/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6898 - metrics_nse: 0.3086\n",
            "Epoch 135/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6732 - metrics_nse: 0.3256\n",
            "Epoch 136/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6639 - metrics_nse: 0.2995\n",
            "Epoch 137/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6837 - metrics_nse: 0.3211\n",
            "Epoch 138/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6219 - metrics_nse: 0.3616\n",
            "Epoch 139/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6191 - metrics_nse: 0.3329\n",
            "Epoch 140/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6178 - metrics_nse: 0.3150\n",
            "Epoch 141/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6024 - metrics_nse: 0.3688\n",
            "Epoch 142/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6130 - metrics_nse: 0.3534\n",
            "Epoch 143/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6348 - metrics_nse: 0.3351\n",
            "Epoch 144/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6187 - metrics_nse: 0.3549\n",
            "Epoch 145/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6422 - metrics_nse: 0.3574\n",
            "Epoch 146/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6001 - metrics_nse: 0.3826\n",
            "Epoch 147/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6034 - metrics_nse: 0.3806\n",
            "Epoch 148/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5817 - metrics_nse: 0.4168\n",
            "Epoch 149/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5797 - metrics_nse: 0.4045\n",
            "Epoch 150/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6273 - metrics_nse: 0.3360\n",
            "Epoch 151/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5969 - metrics_nse: 0.3670\n",
            "Epoch 152/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6091 - metrics_nse: 0.3651\n",
            "Epoch 153/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5866 - metrics_nse: 0.3847\n",
            "Epoch 154/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5886 - metrics_nse: 0.3816\n",
            "Epoch 155/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6032 - metrics_nse: 0.3518\n",
            "Epoch 156/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6233 - metrics_nse: 0.3122\n",
            "Epoch 157/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6192 - metrics_nse: 0.3631\n",
            "Epoch 158/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5952 - metrics_nse: 0.3601\n",
            "Epoch 159/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5877 - metrics_nse: 0.3965\n",
            "Epoch 160/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5892 - metrics_nse: 0.3439\n",
            "Epoch 161/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5779 - metrics_nse: 0.3990\n",
            "Epoch 162/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5929 - metrics_nse: 0.3790\n",
            "Epoch 163/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5827 - metrics_nse: 0.3843\n",
            "Epoch 164/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6113 - metrics_nse: 0.3850\n",
            "Epoch 165/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5961 - metrics_nse: 0.3819\n",
            "Epoch 166/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6119 - metrics_nse: 0.3369\n",
            "Epoch 167/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6032 - metrics_nse: 0.3831\n",
            "Epoch 168/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6066 - metrics_nse: 0.3628\n",
            "Epoch 169/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5918 - metrics_nse: 0.3547\n",
            "Epoch 170/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6069 - metrics_nse: 0.3493\n",
            "Epoch 171/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6033 - metrics_nse: 0.3615\n",
            "Epoch 172/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5812 - metrics_nse: 0.4020\n",
            "Epoch 173/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5983 - metrics_nse: 0.3735\n",
            "Epoch 174/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5698 - metrics_nse: 0.4094\n",
            "Epoch 175/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5711 - metrics_nse: 0.4073\n",
            "Epoch 176/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5893 - metrics_nse: 0.4060\n",
            "Epoch 177/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5636 - metrics_nse: 0.4019\n",
            "Epoch 178/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5472 - metrics_nse: 0.4234\n",
            "Epoch 179/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5593 - metrics_nse: 0.3965\n",
            "Epoch 180/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5862 - metrics_nse: 0.3524\n",
            "Epoch 181/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.6086 - metrics_nse: 0.3227\n",
            "Epoch 182/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5802 - metrics_nse: 0.3524\n",
            "Epoch 183/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5966 - metrics_nse: 0.3991\n",
            "Epoch 184/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5589 - metrics_nse: 0.3820\n",
            "Epoch 185/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5663 - metrics_nse: 0.3919\n",
            "Epoch 186/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5777 - metrics_nse: 0.3513\n",
            "Epoch 187/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5984 - metrics_nse: 0.3814\n",
            "Epoch 188/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6123 - metrics_nse: 0.3294\n",
            "Epoch 189/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5921 - metrics_nse: 0.3815\n",
            "Epoch 190/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5588 - metrics_nse: 0.3929\n",
            "Epoch 191/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5515 - metrics_nse: 0.4547\n",
            "Epoch 192/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5425 - metrics_nse: 0.4365\n",
            "Epoch 193/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5571 - metrics_nse: 0.4375\n",
            "Epoch 194/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5891 - metrics_nse: 0.3727\n",
            "Epoch 195/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5799 - metrics_nse: 0.3747\n",
            "Epoch 196/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5772 - metrics_nse: 0.3680\n",
            "Epoch 197/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5735 - metrics_nse: 0.3444\n",
            "Epoch 198/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5947 - metrics_nse: 0.3601\n",
            "Epoch 199/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5414 - metrics_nse: 0.3988\n",
            "Epoch 200/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5533 - metrics_nse: 0.4051\n",
            "Epoch 201/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5752 - metrics_nse: 0.3975\n",
            "Epoch 202/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5338 - metrics_nse: 0.3964\n",
            "Epoch 203/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5499 - metrics_nse: 0.4248\n",
            "Epoch 204/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5292 - metrics_nse: 0.4389\n",
            "Epoch 205/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5015 - metrics_nse: 0.4469\n",
            "Epoch 206/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5110 - metrics_nse: 0.4751\n",
            "Epoch 207/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5315 - metrics_nse: 0.4396\n",
            "Epoch 208/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5192 - metrics_nse: 0.4531\n",
            "Epoch 209/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5332 - metrics_nse: 0.4276\n",
            "Epoch 210/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5385 - metrics_nse: 0.4256\n",
            "Epoch 211/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5306 - metrics_nse: 0.4196\n",
            "Epoch 212/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5207 - metrics_nse: 0.4406\n",
            "Epoch 213/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5412 - metrics_nse: 0.4136\n",
            "Epoch 214/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5176 - metrics_nse: 0.4708\n",
            "Epoch 215/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5374 - metrics_nse: 0.4628\n",
            "Epoch 216/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5173 - metrics_nse: 0.4545\n",
            "Epoch 217/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5529 - metrics_nse: 0.3740\n",
            "Epoch 218/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5749 - metrics_nse: 0.3869\n",
            "Epoch 219/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5887 - metrics_nse: 0.3619\n",
            "Epoch 220/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5807 - metrics_nse: 0.3370\n",
            "Epoch 221/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5862 - metrics_nse: 0.4050\n",
            "Epoch 222/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5502 - metrics_nse: 0.3935\n",
            "Epoch 223/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5652 - metrics_nse: 0.3956\n",
            "Epoch 224/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5390 - metrics_nse: 0.4351\n",
            "Epoch 225/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5378 - metrics_nse: 0.3756\n",
            "Epoch 226/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5388 - metrics_nse: 0.4370\n",
            "Epoch 227/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5346 - metrics_nse: 0.4346\n",
            "Epoch 228/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5169 - metrics_nse: 0.4216\n",
            "Epoch 229/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5290 - metrics_nse: 0.3612\n",
            "Epoch 230/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5254 - metrics_nse: 0.4113\n",
            "Epoch 231/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5238 - metrics_nse: 0.4613\n",
            "Epoch 232/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5035 - metrics_nse: 0.4212\n",
            "Epoch 233/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5096 - metrics_nse: 0.4252\n",
            "Epoch 234/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5129 - metrics_nse: 0.4455\n",
            "Epoch 235/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5102 - metrics_nse: 0.4623\n",
            "Epoch 236/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4976 - metrics_nse: 0.4683\n",
            "Epoch 237/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5036 - metrics_nse: 0.4354\n",
            "Epoch 238/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5120 - metrics_nse: 0.4411\n",
            "Epoch 239/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5152 - metrics_nse: 0.4288\n",
            "Epoch 240/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5071 - metrics_nse: 0.4679\n",
            "Epoch 241/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5468 - metrics_nse: 0.4280\n",
            "Epoch 242/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4888 - metrics_nse: 0.4566\n",
            "Epoch 243/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5026 - metrics_nse: 0.4273\n",
            "Epoch 244/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5091 - metrics_nse: 0.4299\n",
            "Epoch 245/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5054 - metrics_nse: 0.4538\n",
            "Epoch 246/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5399 - metrics_nse: 0.4111\n",
            "Epoch 247/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5360 - metrics_nse: 0.4365\n",
            "Epoch 248/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5114 - metrics_nse: 0.4120\n",
            "Epoch 249/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5581 - metrics_nse: 0.4235\n",
            "Epoch 250/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5053 - metrics_nse: 0.4614\n",
            "Epoch 251/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5244 - metrics_nse: 0.4347\n",
            "Epoch 252/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5088 - metrics_nse: 0.4203\n",
            "Epoch 253/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5207 - metrics_nse: 0.4400\n",
            "Epoch 254/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5030 - metrics_nse: 0.4498\n",
            "Epoch 255/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4853 - metrics_nse: 0.4718\n",
            "Epoch 256/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5024 - metrics_nse: 0.4524\n",
            "Epoch 257/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5156 - metrics_nse: 0.4490\n",
            "Epoch 258/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5792 - metrics_nse: 0.4013\n",
            "Epoch 259/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5468 - metrics_nse: 0.3936\n",
            "Epoch 260/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5355 - metrics_nse: 0.4366\n",
            "Epoch 261/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5069 - metrics_nse: 0.4385\n",
            "Epoch 262/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4757 - metrics_nse: 0.4871\n",
            "Epoch 263/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4948 - metrics_nse: 0.4365\n",
            "Epoch 264/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4929 - metrics_nse: 0.4438\n",
            "Epoch 265/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4939 - metrics_nse: 0.4291\n",
            "Epoch 266/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4999 - metrics_nse: 0.4302\n",
            "Epoch 267/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4756 - metrics_nse: 0.4351\n",
            "Epoch 268/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4709 - metrics_nse: 0.4660\n",
            "Epoch 269/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4693 - metrics_nse: 0.5050\n",
            "Epoch 270/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5154 - metrics_nse: 0.4231\n",
            "Epoch 271/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4966 - metrics_nse: 0.4519\n",
            "Epoch 272/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4855 - metrics_nse: 0.4217\n",
            "Epoch 273/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4873 - metrics_nse: 0.4631\n",
            "Epoch 274/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4710 - metrics_nse: 0.4980\n",
            "Epoch 275/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4811 - metrics_nse: 0.4977\n",
            "Epoch 276/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4765 - metrics_nse: 0.5004\n",
            "Epoch 277/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5087 - metrics_nse: 0.4469\n",
            "Epoch 278/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4998 - metrics_nse: 0.4846\n",
            "Epoch 279/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4802 - metrics_nse: 0.4698\n",
            "Epoch 280/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4797 - metrics_nse: 0.5110\n",
            "Epoch 281/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4892 - metrics_nse: 0.4688\n",
            "Epoch 282/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4842 - metrics_nse: 0.4454\n",
            "Epoch 283/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4709 - metrics_nse: 0.5114\n",
            "Epoch 284/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4619 - metrics_nse: 0.5006\n",
            "Epoch 285/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5055 - metrics_nse: 0.4500\n",
            "Epoch 286/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4598 - metrics_nse: 0.4865\n",
            "Epoch 287/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4892 - metrics_nse: 0.4781\n",
            "Epoch 288/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4713 - metrics_nse: 0.4554\n",
            "Epoch 289/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4949 - metrics_nse: 0.4436\n",
            "Epoch 290/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4905 - metrics_nse: 0.4549\n",
            "Epoch 291/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4607 - metrics_nse: 0.4728\n",
            "Epoch 292/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4539 - metrics_nse: 0.4790\n",
            "Epoch 293/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4874 - metrics_nse: 0.4736\n",
            "Epoch 294/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4720 - metrics_nse: 0.4782\n",
            "Epoch 295/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4916 - metrics_nse: 0.4750\n",
            "Epoch 296/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4575 - metrics_nse: 0.4907\n",
            "Epoch 297/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4683 - metrics_nse: 0.4901\n",
            "Epoch 298/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4370 - metrics_nse: 0.5197\n",
            "Epoch 299/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4706 - metrics_nse: 0.4624\n",
            "Epoch 300/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4892 - metrics_nse: 0.4941\n",
            "Epoch 301/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4761 - metrics_nse: 0.4886\n",
            "Epoch 302/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4693 - metrics_nse: 0.4558\n",
            "Epoch 303/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4700 - metrics_nse: 0.5021\n",
            "Epoch 304/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4683 - metrics_nse: 0.4604\n",
            "Epoch 305/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4739 - metrics_nse: 0.4998\n",
            "Epoch 306/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4481 - metrics_nse: 0.5118\n",
            "Epoch 307/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4544 - metrics_nse: 0.4698\n",
            "Epoch 308/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4472 - metrics_nse: 0.5027\n",
            "Epoch 309/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4297 - metrics_nse: 0.5442\n",
            "Epoch 310/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4567 - metrics_nse: 0.5036\n",
            "Epoch 311/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4341 - metrics_nse: 0.5326\n",
            "Epoch 312/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4444 - metrics_nse: 0.4958\n",
            "Epoch 313/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4536 - metrics_nse: 0.4817\n",
            "Epoch 314/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4307 - metrics_nse: 0.5311\n",
            "Epoch 315/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4665 - metrics_nse: 0.5171\n",
            "Epoch 316/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4547 - metrics_nse: 0.4651\n",
            "Epoch 317/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4448 - metrics_nse: 0.5220\n",
            "Epoch 318/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4352 - metrics_nse: 0.5296\n",
            "Epoch 319/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4375 - metrics_nse: 0.4793\n",
            "Epoch 320/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4534 - metrics_nse: 0.4728\n",
            "Epoch 321/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4453 - metrics_nse: 0.4647\n",
            "Epoch 322/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4114 - metrics_nse: 0.5232\n",
            "Epoch 323/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4187 - metrics_nse: 0.5443\n",
            "Epoch 324/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4320 - metrics_nse: 0.5111\n",
            "Epoch 325/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4409 - metrics_nse: 0.5180\n",
            "Epoch 326/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4514 - metrics_nse: 0.5003\n",
            "Epoch 327/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4409 - metrics_nse: 0.5392\n",
            "Epoch 328/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4449 - metrics_nse: 0.5088\n",
            "Epoch 329/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4503 - metrics_nse: 0.5237\n",
            "Epoch 330/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4591 - metrics_nse: 0.4735\n",
            "Epoch 331/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5923 - metrics_nse: 0.3639\n",
            "Epoch 332/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5841 - metrics_nse: 0.3796\n",
            "Epoch 333/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.6104 - metrics_nse: 0.3386\n",
            "Epoch 334/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5674 - metrics_nse: 0.3723\n",
            "Epoch 335/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5415 - metrics_nse: 0.3662\n",
            "Epoch 336/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4992 - metrics_nse: 0.4288\n",
            "Epoch 337/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4553 - metrics_nse: 0.4906\n",
            "Epoch 338/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4283 - metrics_nse: 0.4835\n",
            "Epoch 339/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4629 - metrics_nse: 0.4483\n",
            "Epoch 340/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4876 - metrics_nse: 0.4364\n",
            "Epoch 341/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4412 - metrics_nse: 0.5341\n",
            "Epoch 342/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4335 - metrics_nse: 0.4890\n",
            "Epoch 343/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4450 - metrics_nse: 0.4216\n",
            "Epoch 344/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4273 - metrics_nse: 0.4807\n",
            "Epoch 345/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4419 - metrics_nse: 0.4870\n",
            "Epoch 346/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4107 - metrics_nse: 0.5349\n",
            "Epoch 347/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4102 - metrics_nse: 0.5203\n",
            "Epoch 348/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4518 - metrics_nse: 0.5042\n",
            "Epoch 349/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4084 - metrics_nse: 0.5501\n",
            "Epoch 350/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4242 - metrics_nse: 0.5174\n",
            "Epoch 351/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4129 - metrics_nse: 0.4836\n",
            "Epoch 352/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4119 - metrics_nse: 0.5444\n",
            "Epoch 353/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4087 - metrics_nse: 0.5382\n",
            "Epoch 354/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3955 - metrics_nse: 0.5223\n",
            "Epoch 355/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4192 - metrics_nse: 0.5279\n",
            "Epoch 356/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4119 - metrics_nse: 0.5538\n",
            "Epoch 357/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4237 - metrics_nse: 0.5230\n",
            "Epoch 358/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3945 - metrics_nse: 0.5573\n",
            "Epoch 359/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4093 - metrics_nse: 0.5526\n",
            "Epoch 360/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4111 - metrics_nse: 0.5666\n",
            "Epoch 361/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4004 - metrics_nse: 0.5445\n",
            "Epoch 362/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3994 - metrics_nse: 0.5108\n",
            "Epoch 363/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3935 - metrics_nse: 0.5325\n",
            "Epoch 364/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4019 - metrics_nse: 0.5441\n",
            "Epoch 365/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4107 - metrics_nse: 0.5516\n",
            "Epoch 366/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3938 - metrics_nse: 0.5750\n",
            "Epoch 367/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3979 - metrics_nse: 0.5588\n",
            "Epoch 368/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4081 - metrics_nse: 0.4802\n",
            "Epoch 369/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3900 - metrics_nse: 0.5721\n",
            "Epoch 370/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3766 - metrics_nse: 0.5767\n",
            "Epoch 371/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3925 - metrics_nse: 0.5632\n",
            "Epoch 372/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4168 - metrics_nse: 0.5417\n",
            "Epoch 373/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3879 - metrics_nse: 0.5280\n",
            "Epoch 374/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4209 - metrics_nse: 0.5181\n",
            "Epoch 375/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4632 - metrics_nse: 0.4762\n",
            "Epoch 376/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4006 - metrics_nse: 0.5162\n",
            "Epoch 377/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3974 - metrics_nse: 0.5474\n",
            "Epoch 378/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4084 - metrics_nse: 0.5356\n",
            "Epoch 379/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4337 - metrics_nse: 0.4891\n",
            "Epoch 380/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4089 - metrics_nse: 0.5604\n",
            "Epoch 381/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4030 - metrics_nse: 0.5752\n",
            "Epoch 382/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4063 - metrics_nse: 0.5319\n",
            "Epoch 383/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3893 - metrics_nse: 0.5506\n",
            "Epoch 384/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3706 - metrics_nse: 0.5461\n",
            "Epoch 385/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3772 - metrics_nse: 0.5510\n",
            "Epoch 386/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3898 - metrics_nse: 0.5518\n",
            "Epoch 387/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3896 - metrics_nse: 0.5538\n",
            "Epoch 388/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4119 - metrics_nse: 0.5410\n",
            "Epoch 389/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3902 - metrics_nse: 0.5542\n",
            "Epoch 390/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3895 - metrics_nse: 0.5613\n",
            "Epoch 391/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3716 - metrics_nse: 0.5743\n",
            "Epoch 392/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4066 - metrics_nse: 0.5315\n",
            "Epoch 393/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4498 - metrics_nse: 0.4980\n",
            "Epoch 394/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4357 - metrics_nse: 0.5227\n",
            "Epoch 395/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4500 - metrics_nse: 0.5072\n",
            "Epoch 396/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4250 - metrics_nse: 0.4743\n",
            "Epoch 397/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4009 - metrics_nse: 0.5665\n",
            "Epoch 398/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4349 - metrics_nse: 0.4995\n",
            "Epoch 399/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3788 - metrics_nse: 0.5633\n",
            "Epoch 400/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3671 - metrics_nse: 0.5924\n",
            "Epoch 401/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3734 - metrics_nse: 0.5706\n",
            "Epoch 402/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3717 - metrics_nse: 0.5909\n",
            "Epoch 403/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3573 - metrics_nse: 0.5748\n",
            "Epoch 404/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3633 - metrics_nse: 0.5938\n",
            "Epoch 405/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3822 - metrics_nse: 0.5874\n",
            "Epoch 406/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3765 - metrics_nse: 0.5338\n",
            "Epoch 407/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3620 - metrics_nse: 0.5719\n",
            "Epoch 408/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3771 - metrics_nse: 0.5790\n",
            "Epoch 409/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4065 - metrics_nse: 0.5590\n",
            "Epoch 410/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3802 - metrics_nse: 0.5399\n",
            "Epoch 411/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3800 - metrics_nse: 0.5458\n",
            "Epoch 412/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4417 - metrics_nse: 0.4704\n",
            "Epoch 413/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3734 - metrics_nse: 0.5887\n",
            "Epoch 414/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3854 - metrics_nse: 0.5562\n",
            "Epoch 415/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3725 - metrics_nse: 0.6036\n",
            "Epoch 416/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3782 - metrics_nse: 0.5644\n",
            "Epoch 417/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3620 - metrics_nse: 0.5976\n",
            "Epoch 418/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3427 - metrics_nse: 0.5679\n",
            "Epoch 419/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3378 - metrics_nse: 0.5883\n",
            "Epoch 420/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3412 - metrics_nse: 0.6108\n",
            "Epoch 421/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3408 - metrics_nse: 0.6021\n",
            "Epoch 422/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3481 - metrics_nse: 0.5705\n",
            "Epoch 423/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3412 - metrics_nse: 0.5890\n",
            "Epoch 424/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3682 - metrics_nse: 0.5628\n",
            "Epoch 425/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3629 - metrics_nse: 0.5878\n",
            "Epoch 426/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3428 - metrics_nse: 0.6168\n",
            "Epoch 427/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3375 - metrics_nse: 0.6427\n",
            "Epoch 428/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3442 - metrics_nse: 0.6283\n",
            "Epoch 429/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3479 - metrics_nse: 0.5848\n",
            "Epoch 430/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3719 - metrics_nse: 0.6044\n",
            "Epoch 431/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3672 - metrics_nse: 0.6102\n",
            "Epoch 432/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3778 - metrics_nse: 0.6086\n",
            "Epoch 433/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3935 - metrics_nse: 0.5841\n",
            "Epoch 434/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3629 - metrics_nse: 0.5992\n",
            "Epoch 435/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4129 - metrics_nse: 0.4621\n",
            "Epoch 436/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3882 - metrics_nse: 0.4990\n",
            "Epoch 437/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3647 - metrics_nse: 0.5197\n",
            "Epoch 438/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3675 - metrics_nse: 0.5936\n",
            "Epoch 439/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3667 - metrics_nse: 0.5710\n",
            "Epoch 440/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3485 - metrics_nse: 0.6027\n",
            "Epoch 441/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3391 - metrics_nse: 0.6228\n",
            "Epoch 442/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3417 - metrics_nse: 0.5904\n",
            "Epoch 443/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3411 - metrics_nse: 0.5988\n",
            "Epoch 444/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3437 - metrics_nse: 0.5580\n",
            "Epoch 445/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3972 - metrics_nse: 0.5556\n",
            "Epoch 446/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3760 - metrics_nse: 0.5669\n",
            "Epoch 447/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3806 - metrics_nse: 0.5614\n",
            "Epoch 448/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3410 - metrics_nse: 0.5568\n",
            "Epoch 449/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3183 - metrics_nse: 0.6642\n",
            "Epoch 450/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3132 - metrics_nse: 0.5905\n",
            "Epoch 451/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3400 - metrics_nse: 0.5910\n",
            "Epoch 452/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3256 - metrics_nse: 0.6437\n",
            "Epoch 453/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3515 - metrics_nse: 0.6107\n",
            "Epoch 454/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3136 - metrics_nse: 0.6616\n",
            "Epoch 455/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3197 - metrics_nse: 0.6170\n",
            "Epoch 456/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3290 - metrics_nse: 0.5735\n",
            "Epoch 457/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3005 - metrics_nse: 0.6279\n",
            "Epoch 458/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3284 - metrics_nse: 0.5900\n",
            "Epoch 459/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3375 - metrics_nse: 0.5925\n",
            "Epoch 460/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3081 - metrics_nse: 0.6439\n",
            "Epoch 461/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3323 - metrics_nse: 0.6151\n",
            "Epoch 462/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3321 - metrics_nse: 0.5949\n",
            "Epoch 463/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3226 - metrics_nse: 0.6290\n",
            "Epoch 464/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3231 - metrics_nse: 0.6131\n",
            "Epoch 465/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3241 - metrics_nse: 0.6205\n",
            "Epoch 466/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3214 - metrics_nse: 0.6285\n",
            "Epoch 467/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3151 - metrics_nse: 0.6678\n",
            "Epoch 468/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3551 - metrics_nse: 0.5906\n",
            "Epoch 469/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3299 - metrics_nse: 0.5980\n",
            "Epoch 470/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3229 - metrics_nse: 0.6469\n",
            "Epoch 471/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3457 - metrics_nse: 0.6297\n",
            "Epoch 472/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3356 - metrics_nse: 0.6256\n",
            "Epoch 473/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2994 - metrics_nse: 0.6099\n",
            "Epoch 474/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3546 - metrics_nse: 0.6232\n",
            "Epoch 475/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3278 - metrics_nse: 0.5711\n",
            "Epoch 476/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3117 - metrics_nse: 0.6371\n",
            "Epoch 477/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3226 - metrics_nse: 0.6111\n",
            "Epoch 478/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3012 - metrics_nse: 0.6409\n",
            "Epoch 479/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3108 - metrics_nse: 0.6360\n",
            "Epoch 480/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3227 - metrics_nse: 0.5670\n",
            "Epoch 481/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2990 - metrics_nse: 0.6518\n",
            "Epoch 482/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3088 - metrics_nse: 0.6375\n",
            "Epoch 483/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3232 - metrics_nse: 0.6601\n",
            "Epoch 484/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3200 - metrics_nse: 0.6134\n",
            "Epoch 485/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3252 - metrics_nse: 0.6123\n",
            "Epoch 486/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3047 - metrics_nse: 0.6162\n",
            "Epoch 487/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3089 - metrics_nse: 0.6377\n",
            "Epoch 488/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3041 - metrics_nse: 0.6569\n",
            "Epoch 489/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3195 - metrics_nse: 0.6127\n",
            "Epoch 490/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3054 - metrics_nse: 0.6025\n",
            "Epoch 491/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3030 - metrics_nse: 0.6774\n",
            "Epoch 492/500\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.3226 - metrics_nse: 0.5888\n",
            "Epoch 493/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2949 - metrics_nse: 0.6591\n",
            "Epoch 494/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3167 - metrics_nse: 0.6430\n",
            "Epoch 495/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3204 - metrics_nse: 0.6250\n",
            "Epoch 496/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3043 - metrics_nse: 0.5910\n",
            "Epoch 497/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3373 - metrics_nse: 0.5822\n",
            "Epoch 498/500\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3400 - metrics_nse: 0.5290\n",
            "Epoch 499/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3999 - metrics_nse: 0.5392\n",
            "Epoch 500/500\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.4386 - metrics_nse: 0.4374\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f815d108d90>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=prediction(model, x_test_transformed)\n",
        "nse_val = get_nse(y_test_transformed, predictions) "
      ],
      "metadata": {
        "id": "4BYPFu7mLt0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nse\n",
        "#plt.plot( predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87Q2aWH6R3lC",
        "outputId": "be164c22-da03-4128-9ed6-774da2891b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-7.141469688013502e+39"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obs = y_test_transformed\n",
        "sim = predictions\n",
        "\n",
        "denom = np.sum(obs-np.mean(obs))**2\n",
        "nom = np.sum(obs-sim)**2\n",
        "nse = 1- nom/denom\n",
        "nse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHAgt_CPSfzs",
        "outputId": "a518d3c0-4dee-46f1-b1e4-ca50fdb57ad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-7.141469688013502e+39"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FOfd62eJUu6"
      },
      "source": [
        "## Routine implementation\n",
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmvIGC9KJbBT",
        "outputId": "3a859d6f-0d30-4324-d46f-4796e26bcb4a"
      },
      "source": [
        "RNN='LSTM'\n",
        "\n",
        "### Specify HUC of interest ###\n",
        "HUC_ID = '1'\n",
        "# Define path for daymet\n",
        "start_path_daymet = '/content/drive/My Drive/Colab Notebooks/basin_mean_forcing/daymet'\n",
        "final_path_daymet = os.path.join(start_path_daymet, HUC_ID, '*.txt')\n",
        "#define path for streamflow\n",
        "start_path_flow = '/content/drive/My Drive/Colab Notebooks/usgs_streamflow'\n",
        "final_path_flow = os.path.join(start_path_flow, HUC_ID, '*.txt')\n",
        "# Create List with all filenames (all catchments in HUC)\n",
        "catchments_daymet = []\n",
        "catchments_flow = []\n",
        "for file in glob.glob(final_path_daymet):\n",
        "    catchments_daymet.append(file)\n",
        "for file in glob.glob(final_path_flow):\n",
        "  catchments_flow.append(file)\n",
        "# Create empty list to store model results in\n",
        "df_result = []\n",
        "\n",
        "### METRICS\n",
        "loss = 'mse'\n",
        "metrics = metrics_nse\n",
        "### HYPERPARAMETER ###\n",
        "t = 365 #lag time(days) input\n",
        "epochs = 50\n",
        "batch_size = 512\n",
        "\n",
        "############# START OF LOOPING THE MODEL FOR ALL CATCHMENTS IN HUC #############\n",
        "for i in range(len(catchments_daymet)):\n",
        "\n",
        "  print('--------Loading Data...........................................................')\n",
        "  # get path\n",
        "  filename_daymet = catchments_daymet[i]\n",
        "  # get catchmennt ID\n",
        "  catchment_ID = os.path.basename(filename_daymet).split('_', 1)[0]\n",
        "  #get path\n",
        "  filename_flow = [s for s in catchments_flow if catchment_ID in s]\n",
        "  # load data\n",
        "  data = read_data(filename_daymet, filename_flow[0])\n",
        "  print('--------Data-loading complete--------------------------------------------------')\n",
        "  print('--------Creating Training and Test samples.....................................')\n",
        "  # Split Train and Test Data\n",
        "  df_train, df_test = split_data1(data)\n",
        "  # Standardize data\n",
        "  ############ Question how to standardize: [a]=by using statistical values of training set (best when stats of both sets do not differ), [b]=by using training stats for training set and testing stats for test set, [c]=by using complete set stats (worst)\n",
        "  print('--------Standardizing data.....................................................')\n",
        "  scaled_train, train_std, train_mean = local_standartization(df_train)\n",
        "  scaled_test = scale(df_test, train_std, train_mean)\n",
        "  # split data\n",
        "  y_train_sc, x_train_sc, y_test_sc, x_test_sc = split_data(scaled_train, scaled_test)\n",
        "  # create sequences\n",
        "  print('--------Shaping sequences......................................................')\n",
        "  num_steps = 365\n",
        "  # training set\n",
        "  (x_train_transformed,\n",
        "  y_train_transformed) = lstm_data_transform(x_train_sc, y_train_sc, num_steps=num_steps)\n",
        "  assert x_train_transformed.shape[0] == y_train_transformed.shape[0]\n",
        "  # test set\n",
        "  (x_test_transformed,\n",
        "  y_test_transformed) = lstm_data_transform(x_test_sc, y_test_sc, num_steps=num_steps)\n",
        "  assert x_test_transformed.shape[0] == y_test_transformed.shape[0]\n",
        "  # initate and compile model, \n",
        "  model = model_lstm(x_train_transformed, loss, metrics)\n",
        "  print('--------START TRAINING OF CATCHMENT '+catchment_ID+' in HUC '+HUC_ID+'--------')\n",
        "  #print('--------Training period: 1981/10/01 - 1995/09/30------------------------------')\n",
        "  # train model\n",
        "  model.fit(x_train_transformed, y_train_transformed, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
        "  # accuracy\n",
        "  #accuracy = get_accuracy(model,x_train_transformed,y_train_transformed)\n",
        "  print('--------End of Training-------------------------------------------------------')\n",
        "  print('--------Start of Evaluation---------------------------------------------------')\n",
        "  #print('--------Evaluation period : '+df_test.ix[0]+'-'+df_test.ix[-1]+'-------------------------------')\n",
        "  # validation\n",
        "  predictions= prediction(model, x_test_transformed)\n",
        "  train_output = prediction(model, x_train_transformed)\n",
        "  nse_val = get_nse(y_test_transformed, predictions)\n",
        "  nse_train = get_nse(y_train_transformed, train_output)\n",
        "  print('Training NSE = ', nse_train)\n",
        "  print('Validation NSE =', nse_val)\n",
        "  #print('Validation accuracy (NSE) = ' +nse_val+'-----')\n",
        "  #store paramters \n",
        "  df_result.append([catchment_ID, nse_train, nse_val])\n",
        "  #print predicitons \n",
        "  # create dfs containing model output and observed values (features, and targets)\n",
        "  pred_rescaled = rescale(predictions, train_std, train_mean)\n",
        "  train_rescaled = rescale(train_output, train_std, train_mean)\n",
        "  df_test_short = df_test.iloc[365:,:]\n",
        "  df_test_short['predictions']= pred_rescaled\n",
        "  df_train_short = df_train.iloc[365:,:]\n",
        "  df_train_short['predictions']= train_rescaled\n",
        "  #df_test = df_test['1996-01-02':'2010-01-01']\n",
        "  # plot example\n",
        "  #fig=plt.figure(figsize=(7, 5), dpi= 150, facecolor='w', edgecolor='k')\n",
        "  #plt.plot(df_test.index, df_test['Q_spec(mm)'])\n",
        "  #plt.ylabel('discharge Q_spec(mm)')\n",
        "  #plt.plot(df_test.index, pred_rescaled.flatten(), alpha=0.5)\n",
        "  #plt.show()\n",
        "  # save weights\n",
        "  os.chdir('/content/drive/My Drive/Colab Notebooks/Experiment1/'+RNN+'/loss_MSE/weights')\n",
        "  model.save_weights(catchment_ID+'_model.h5')\n",
        "  # save model input and output dataframes\n",
        "  os.chdir('/content/drive/My Drive/Colab Notebooks/Experiment1/'+RNN+'/loss_MSE/model_predictions')\n",
        "  df_test_short.to_csv(catchment_ID+'_test_pred.csv')\n",
        "  df_train_short.to_csv(catchment_ID+'_train_pred.csv')\n",
        "\n",
        "#initialise dataframe\n",
        "df_result = pd.DataFrame(df_result, columns=['catchment_ID', 'nse_train', 'nse_val'])\n",
        "#define current directory\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Experiment1/'+RNN+'/loss_MSE/results')\n",
        "#save dataframe with results\n",
        "df_result.to_csv(HUC_ID+RNN+'_results.csv')\n",
        "# Show results\n",
        "print(df_result)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [catchment_ID, nse_train, nse_val]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Routine implementation\n",
        "GRU\n"
      ],
      "metadata": {
        "id": "KB3T5EJYar2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### \n",
        "\n",
        "RNN = \"GRU\"\n",
        "\n",
        "### Specify HUC of interest ###\n",
        "HUC_ID = '17'\n",
        "# Define path for daymet\n",
        "start_path_daymet = '/content/drive/My Drive/Colab Notebooks/basin_mean_forcing/daymet'\n",
        "final_path_daymet = os.path.join(start_path_daymet, HUC_ID, '*.txt')\n",
        "#define path for streamflow\n",
        "start_path_flow = '/content/drive/My Drive/Colab Notebooks/usgs_streamflow'\n",
        "final_path_flow = os.path.join(start_path_flow, HUC_ID, '*.txt')\n",
        "# Create List with all filenames (all catchments in HUC)\n",
        "catchments_daymet = []\n",
        "catchments_flow = []\n",
        "for file in glob.glob(final_path_daymet):\n",
        "    catchments_daymet.append(file)\n",
        "for file in glob.glob(final_path_flow):\n",
        "  catchments_flow.append(file)\n",
        "# Create empty list to store model results in\n",
        "df_result = []\n",
        "\n",
        "### METRICS\n",
        "loss = 'mse'\n",
        "metrics = metrics_nse\n",
        "### HYPERPARAMETER ###\n",
        "t = 365 #lag time(days) input\n",
        "epochs = 50\n",
        "batch_size = 512\n",
        "\n",
        "############# START OF LOOPING THE MODEL FOR ALL CATCHMENTS IN HUC #############\n",
        "for i in range(len(catchments_daymet)):\n",
        "\n",
        "  print('--------Loading Data...........................................................')\n",
        "  # get path\n",
        "  filename_daymet = catchments_daymet[i]\n",
        "  # get catchmennt ID\n",
        "  catchment_ID = os.path.basename(filename_daymet).split('_', 1)[0]\n",
        "  #get path\n",
        "  filename_flow = [s for s in catchments_flow if catchment_ID in s]\n",
        "  # load data\n",
        "  data = read_data(filename_daymet, filename_flow[0])\n",
        "  print('--------Data-loading complete--------------------------------------------------')\n",
        "  print('--------Creating Training and Test samples.....................................')\n",
        "  # Split Train and Test Data\n",
        "  df_train, df_test = split_data1(data)\n",
        "  # Standardize data\n",
        "  ############ Question how to standardize: [a]=by using statistical values of training set (best when stats of both sets do not differ), [b]=by using training stats for training set and testing stats for test set, [c]=by using complete set stats (worst)\n",
        "  print('--------Standardizing data.....................................................')\n",
        "  scaled_train, train_std, train_mean = local_standartization(df_train)\n",
        "  scaled_test = scale(df_test, train_std, train_mean)\n",
        "  # split data\n",
        "  y_train_sc, x_train_sc, y_test_sc, x_test_sc = split_data(scaled_train, scaled_test)\n",
        "  # create sequences\n",
        "  print('--------Shaping sequences......................................................')\n",
        "  num_steps = 365\n",
        "  # training set\n",
        "  (x_train_transformed,\n",
        "  y_train_transformed) = lstm_data_transform(x_train_sc, y_train_sc, num_steps=num_steps)\n",
        "  assert x_train_transformed.shape[0] == y_train_transformed.shape[0]\n",
        "  # test set\n",
        "  (x_test_transformed,\n",
        "  y_test_transformed) = lstm_data_transform(x_test_sc, y_test_sc, num_steps=num_steps)\n",
        "  assert x_test_transformed.shape[0] == y_test_transformed.shape[0]\n",
        "  # initate and compile model, \n",
        "  model = model_gru(x_train_transformed, loss, metrics)\n",
        "  print('--------START TRAINING OF CATCHMENT '+catchment_ID+' in HUC '+HUC_ID+'--------')\n",
        "  print('--------Training period: 1981/10/01 - 1995/09/30------------------------------')\n",
        "  # train model\n",
        "  model.fit(x_train_transformed, y_train_transformed, epochs=epochs, batch_size=batch_size, verbose=1, shuffle=True)\n",
        "  # accuracy\n",
        "  #accuracy = get_accuracy(model,x_train_transformed,y_train_transformed)\n",
        "  print('--------End of Training-------------------------------------------------------')\n",
        "  print('--------Start of Evaluation---------------------------------------------------')\n",
        "  print('--------Evaluation period 1996/10/01-2010/09/30-------------------------------')\n",
        "  # validation\n",
        "  predictions= prediction(model, x_test_transformed)\n",
        "  train_output = prediction(model, x_train_transformed)\n",
        "  nse_val = get_nse(y_test_transformed, predictions)\n",
        "  nse_train = get_nse(y_train_transformed, train_output)\n",
        "  print('Training NSE = ', nse_train)\n",
        "  print('Validation NSE =', nse_val)\n",
        "  #print('Validation accuracy (NSE) = ' +nse_val+'-----')\n",
        "  #store paramters \n",
        "  df_result.append([catchment_ID, nse_train, nse_val])\n",
        "  #print predicitons \n",
        "  #pred_rescaled = rescale(predictions, train_mean, train_std)\n",
        "  #df_test = df_test['1996-01-02':'2010-01-01']\n",
        "  # plot example\n",
        "  #fig=plt.figure(figsize=(7, 5), dpi= 150, facecolor='w', edgecolor='k')\n",
        "  #plt.plot(df_test.index, df_test['Q_spec(mm)'])\n",
        "  #plt.ylabel('discharge Q_spec(mm)')\n",
        "  #plt.plot(df_test.index, pred_rescaled.flatten(), alpha=0.5)\n",
        "  #plt.show()\n",
        "  # save weights\n",
        "  os.chdir('/content/drive/My Drive/Colab Notebooks/Experiment1/'+RNN+'/loss_MSE')\n",
        "  model.save_weights(HUC_ID+'_'+catchment_ID+RNN+'_model.h5')\n",
        "\n",
        "#initialise dataframe\n",
        "df_result = pd.DataFrame(df_result, columns=['catchment_ID', 'nse_train', 'nse_val'])\n",
        "#define current directory\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/Experiment1/'+RNN+'/loss_MSE')\n",
        "#save dataframe with results\n",
        "df_result.to_csv(HUC_ID+RNN+'_results.csv')\n",
        "# Show results\n",
        "print(df_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgm0FBxQaw3r",
        "outputId": "0883b1e1-4348-4ef6-e43f-a6fdc0de2909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3184 - metrics_nse: 0.6971\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3133 - metrics_nse: 0.7010\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3077 - metrics_nse: 0.7068\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3098 - metrics_nse: 0.7048\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3077 - metrics_nse: 0.7025\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3059 - metrics_nse: 0.7075\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.2962 - metrics_nse: 0.7121\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2998 - metrics_nse: 0.7133\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2940 - metrics_nse: 0.7200\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2985 - metrics_nse: 0.7106\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2925 - metrics_nse: 0.7281\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2975 - metrics_nse: 0.7166\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2847 - metrics_nse: 0.7309\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2827 - metrics_nse: 0.7277\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2810 - metrics_nse: 0.7362\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2843 - metrics_nse: 0.7385\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2858 - metrics_nse: 0.7315\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2765 - metrics_nse: 0.7372\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2736 - metrics_nse: 0.7413\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2731 - metrics_nse: 0.7448\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2703 - metrics_nse: 0.7467\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2695 - metrics_nse: 0.7399\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2673 - metrics_nse: 0.7501\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2633 - metrics_nse: 0.7462\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2638 - metrics_nse: 0.7550\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2592 - metrics_nse: 0.7547\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2620 - metrics_nse: 0.7509\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2607 - metrics_nse: 0.7582\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2506 - metrics_nse: 0.7627\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2522 - metrics_nse: 0.7609\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.7743362]\n",
            "Validation NSE = [0.6610194]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_220\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_434 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_434 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_435 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_435 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_217 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12054000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 49ms/step - loss: 0.9305 - metrics_nse: 0.0466\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8210 - metrics_nse: 0.1592\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7648 - metrics_nse: 0.2178\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7167 - metrics_nse: 0.2694\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6978 - metrics_nse: 0.2854\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6752 - metrics_nse: 0.3097\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6541 - metrics_nse: 0.3362\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.6386 - metrics_nse: 0.3412\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6238 - metrics_nse: 0.3629\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6090 - metrics_nse: 0.3794\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5921 - metrics_nse: 0.3982\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5889 - metrics_nse: 0.3946\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5793 - metrics_nse: 0.4110\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5668 - metrics_nse: 0.4188\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5587 - metrics_nse: 0.4217\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5540 - metrics_nse: 0.4389\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5476 - metrics_nse: 0.4471\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5327 - metrics_nse: 0.4528\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5327 - metrics_nse: 0.4523\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5253 - metrics_nse: 0.4616\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5140 - metrics_nse: 0.4775\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5025 - metrics_nse: 0.4874\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5109 - metrics_nse: 0.4781\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5030 - metrics_nse: 0.4889\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4925 - metrics_nse: 0.4987\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4941 - metrics_nse: 0.5005\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4818 - metrics_nse: 0.5120\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4911 - metrics_nse: 0.5029\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4849 - metrics_nse: 0.5079\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4720 - metrics_nse: 0.5181\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4755 - metrics_nse: 0.5146\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4692 - metrics_nse: 0.5175\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4702 - metrics_nse: 0.5169\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4641 - metrics_nse: 0.5288\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4622 - metrics_nse: 0.5342\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4632 - metrics_nse: 0.5313\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.4541 - metrics_nse: 0.5452\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4518 - metrics_nse: 0.5449\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4542 - metrics_nse: 0.5404\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4483 - metrics_nse: 0.5452\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4378 - metrics_nse: 0.5519\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4471 - metrics_nse: 0.5481\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4428 - metrics_nse: 0.5500\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4312 - metrics_nse: 0.5531\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4401 - metrics_nse: 0.5613\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4254 - metrics_nse: 0.5685\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4253 - metrics_nse: 0.5707\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4323 - metrics_nse: 0.5505\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4315 - metrics_nse: 0.5634\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4305 - metrics_nse: 0.5605\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.58751225]\n",
            "Validation NSE = [0.4638499]\n",
            "--------Loading Data...........................................................\n",
            "43 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_221\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_436 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_436 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_437 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_437 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12041200 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 48ms/step - loss: 0.8006 - metrics_nse: 0.1579\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6882 - metrics_nse: 0.2817\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6270 - metrics_nse: 0.3479\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5985 - metrics_nse: 0.3770\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5714 - metrics_nse: 0.4030\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5603 - metrics_nse: 0.4182\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5439 - metrics_nse: 0.4321\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5247 - metrics_nse: 0.4516\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5256 - metrics_nse: 0.4486\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5058 - metrics_nse: 0.4732\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5005 - metrics_nse: 0.4791\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4951 - metrics_nse: 0.4797\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4783 - metrics_nse: 0.5032\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4825 - metrics_nse: 0.4994\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4687 - metrics_nse: 0.5220\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4678 - metrics_nse: 0.5055\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4602 - metrics_nse: 0.5218\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4491 - metrics_nse: 0.5298\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4543 - metrics_nse: 0.5177\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4468 - metrics_nse: 0.5354\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4528 - metrics_nse: 0.5258\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4366 - metrics_nse: 0.5474\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4372 - metrics_nse: 0.5414\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4352 - metrics_nse: 0.5604\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4335 - metrics_nse: 0.5487\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4327 - metrics_nse: 0.5504\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4254 - metrics_nse: 0.5532\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4283 - metrics_nse: 0.5554\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4253 - metrics_nse: 0.5606\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4315 - metrics_nse: 0.5577\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.4227 - metrics_nse: 0.5715\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4195 - metrics_nse: 0.5684\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4180 - metrics_nse: 0.5590\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4161 - metrics_nse: 0.5643\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4249 - metrics_nse: 0.5622\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4103 - metrics_nse: 0.5743\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4191 - metrics_nse: 0.5665\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4118 - metrics_nse: 0.5761\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4135 - metrics_nse: 0.5752\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4153 - metrics_nse: 0.5628\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4116 - metrics_nse: 0.5698\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4130 - metrics_nse: 0.5694\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4092 - metrics_nse: 0.5747\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4109 - metrics_nse: 0.5714\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3947 - metrics_nse: 0.5797\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4114 - metrics_nse: 0.5868\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4054 - metrics_nse: 0.5807\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4120 - metrics_nse: 0.5748\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4114 - metrics_nse: 0.5730\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4046 - metrics_nse: 0.5806\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.5883937]\n",
            "Validation NSE = [0.5920832]\n",
            "--------Loading Data...........................................................\n",
            "1277 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_222\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_438 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_438 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_439 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_439 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14362250 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 49ms/step - loss: 1.0159 - metrics_nse: 0.0355\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.9792 - metrics_nse: 0.0736\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9627 - metrics_nse: 0.1132\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9552 - metrics_nse: 0.1172\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9542 - metrics_nse: 0.1188\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9512 - metrics_nse: 0.1309\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9492 - metrics_nse: 0.1451\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.9406 - metrics_nse: 0.1294\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9456 - metrics_nse: 0.1543\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9367 - metrics_nse: 0.1444\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9352 - metrics_nse: 0.1321\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9279 - metrics_nse: 0.1494\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9246 - metrics_nse: 0.1479\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9300 - metrics_nse: 0.1598\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9254 - metrics_nse: 0.1570\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9244 - metrics_nse: 0.1296\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.9190 - metrics_nse: 0.1665\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.9154 - metrics_nse: 0.1645\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9062 - metrics_nse: 0.1747\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.9056 - metrics_nse: 0.1902\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.8898 - metrics_nse: 0.2011\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8922 - metrics_nse: 0.2078\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8747 - metrics_nse: 0.2150\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8773 - metrics_nse: 0.2039\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8628 - metrics_nse: 0.2274\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8598 - metrics_nse: 0.2307\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8439 - metrics_nse: 0.2303\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8115 - metrics_nse: 0.2783\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.8070 - metrics_nse: 0.2682\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8016 - metrics_nse: 0.2787\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7651 - metrics_nse: 0.3085\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7464 - metrics_nse: 0.3341\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7313 - metrics_nse: 0.3673\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.7130 - metrics_nse: 0.3881\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7099 - metrics_nse: 0.3826\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7624 - metrics_nse: 0.3241\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7222 - metrics_nse: 0.3346\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7215 - metrics_nse: 0.3737\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6997 - metrics_nse: 0.4001\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7052 - metrics_nse: 0.3688\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6922 - metrics_nse: 0.4140\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6810 - metrics_nse: 0.4102\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6876 - metrics_nse: 0.4243\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6793 - metrics_nse: 0.3924\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.6774 - metrics_nse: 0.4142\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6773 - metrics_nse: 0.4152\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6846 - metrics_nse: 0.4038\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6704 - metrics_nse: 0.4031\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6779 - metrics_nse: 0.4211\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6575 - metrics_nse: 0.4448\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.379494]\n",
            "Validation NSE = [-0.67118704]\n",
            "--------Loading Data...........................................................\n",
            "85 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_223\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_440 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_440 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_441 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_441 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_220 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14138870 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 4s 50ms/step - loss: 1.0726 - metrics_nse: -0.0728\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7658 - metrics_nse: 0.2420\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6805 - metrics_nse: 0.3196\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6184 - metrics_nse: 0.3863\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5662 - metrics_nse: 0.4410\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5260 - metrics_nse: 0.4807\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4974 - metrics_nse: 0.5073\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4856 - metrics_nse: 0.5242\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4694 - metrics_nse: 0.5325\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4458 - metrics_nse: 0.5529\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4327 - metrics_nse: 0.5712\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4212 - metrics_nse: 0.5815\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4110 - metrics_nse: 0.5908\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4042 - metrics_nse: 0.6000\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3887 - metrics_nse: 0.6217\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3865 - metrics_nse: 0.6190\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3817 - metrics_nse: 0.6155\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3783 - metrics_nse: 0.6242\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3719 - metrics_nse: 0.6280\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3670 - metrics_nse: 0.6283\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3471 - metrics_nse: 0.6445\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3582 - metrics_nse: 0.6419\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3557 - metrics_nse: 0.6497\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3504 - metrics_nse: 0.6503\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3464 - metrics_nse: 0.6571\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3407 - metrics_nse: 0.6575\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3474 - metrics_nse: 0.6515\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3365 - metrics_nse: 0.6626\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3322 - metrics_nse: 0.6693\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3275 - metrics_nse: 0.6740\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3271 - metrics_nse: 0.6757\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3248 - metrics_nse: 0.6778\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3145 - metrics_nse: 0.6872\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3154 - metrics_nse: 0.6869\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3120 - metrics_nse: 0.6901\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3159 - metrics_nse: 0.6852\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3120 - metrics_nse: 0.6890\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3027 - metrics_nse: 0.6990\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3084 - metrics_nse: 0.6880\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3036 - metrics_nse: 0.6970\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3087 - metrics_nse: 0.6913\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3035 - metrics_nse: 0.7009\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3010 - metrics_nse: 0.6984\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3007 - metrics_nse: 0.6993\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3034 - metrics_nse: 0.6969\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2988 - metrics_nse: 0.6979\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3003 - metrics_nse: 0.7028\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2915 - metrics_nse: 0.7069\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2906 - metrics_nse: 0.7009\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2839 - metrics_nse: 0.7157\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.730566]\n",
            "Validation NSE = [0.61610055]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_224\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_442 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_442 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_443 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_443 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12147600 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 52ms/step - loss: 0.9798 - metrics_nse: -0.0136\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8762 - metrics_nse: 0.0987\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8173 - metrics_nse: 0.1596\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7878 - metrics_nse: 0.1874\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7589 - metrics_nse: 0.2252\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7397 - metrics_nse: 0.2434\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7258 - metrics_nse: 0.2634\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7054 - metrics_nse: 0.2787\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6904 - metrics_nse: 0.2928\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6771 - metrics_nse: 0.3068\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6593 - metrics_nse: 0.3238\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6520 - metrics_nse: 0.3315\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6513 - metrics_nse: 0.3333\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.6497 - metrics_nse: 0.3376\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6292 - metrics_nse: 0.3524\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6337 - metrics_nse: 0.3499\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6250 - metrics_nse: 0.3518\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6244 - metrics_nse: 0.3648\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6153 - metrics_nse: 0.3717\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6150 - metrics_nse: 0.3695\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6116 - metrics_nse: 0.3755\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6169 - metrics_nse: 0.3661\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6080 - metrics_nse: 0.3789\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6019 - metrics_nse: 0.3889\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6008 - metrics_nse: 0.3818\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6060 - metrics_nse: 0.3769\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5933 - metrics_nse: 0.3855\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5994 - metrics_nse: 0.3733\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5944 - metrics_nse: 0.3895\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5931 - metrics_nse: 0.3916\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5859 - metrics_nse: 0.3902\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5976 - metrics_nse: 0.3934\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5920 - metrics_nse: 0.3936\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5852 - metrics_nse: 0.3985\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5844 - metrics_nse: 0.3959\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5917 - metrics_nse: 0.3914\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5745 - metrics_nse: 0.4232\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5725 - metrics_nse: 0.4084\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5842 - metrics_nse: 0.4024\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5800 - metrics_nse: 0.4160\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5781 - metrics_nse: 0.4009\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5789 - metrics_nse: 0.4090\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5798 - metrics_nse: 0.4074\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5706 - metrics_nse: 0.4207\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5680 - metrics_nse: 0.4122\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5673 - metrics_nse: 0.4161\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5658 - metrics_nse: 0.4232\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5689 - metrics_nse: 0.4144\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5628 - metrics_nse: 0.4229\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5578 - metrics_nse: 0.4373\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.44137144]\n",
            "Validation NSE = [0.3311634]\n",
            "--------Loading Data...........................................................\n",
            "1349 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_225\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_444 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_444 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_445 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_445 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14306340 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 50ms/step - loss: 1.1191 - metrics_nse: -0.1304\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8532 - metrics_nse: 0.1433\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8217 - metrics_nse: 0.1814\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8005 - metrics_nse: 0.1994\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7895 - metrics_nse: 0.2073\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7865 - metrics_nse: 0.2114\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7763 - metrics_nse: 0.2256\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7746 - metrics_nse: 0.2320\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7671 - metrics_nse: 0.2324\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7675 - metrics_nse: 0.2337\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7566 - metrics_nse: 0.2483\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7543 - metrics_nse: 0.2470\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7494 - metrics_nse: 0.2478\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7459 - metrics_nse: 0.2654\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7477 - metrics_nse: 0.2519\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7415 - metrics_nse: 0.2593\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7435 - metrics_nse: 0.2537\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7365 - metrics_nse: 0.2650\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7240 - metrics_nse: 0.2764\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7307 - metrics_nse: 0.2685\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7246 - metrics_nse: 0.2748\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.7269 - metrics_nse: 0.2753\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7276 - metrics_nse: 0.2746\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7090 - metrics_nse: 0.2868\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7074 - metrics_nse: 0.2900\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7075 - metrics_nse: 0.2883\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7024 - metrics_nse: 0.3016\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7058 - metrics_nse: 0.2988\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7000 - metrics_nse: 0.3003\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7003 - metrics_nse: 0.3047\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7007 - metrics_nse: 0.2984\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6976 - metrics_nse: 0.3050\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6803 - metrics_nse: 0.3177\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6888 - metrics_nse: 0.3101\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6860 - metrics_nse: 0.3180\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.6909 - metrics_nse: 0.3071\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6763 - metrics_nse: 0.3217\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6732 - metrics_nse: 0.3247\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6771 - metrics_nse: 0.3200\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6694 - metrics_nse: 0.3302\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6658 - metrics_nse: 0.3318\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6680 - metrics_nse: 0.3257\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.6692 - metrics_nse: 0.3311\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6603 - metrics_nse: 0.3408\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6708 - metrics_nse: 0.3275\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6660 - metrics_nse: 0.3357\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6454 - metrics_nse: 0.3511\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6421 - metrics_nse: 0.3520\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6379 - metrics_nse: 0.3601\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6252 - metrics_nse: 0.3688\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.3846709]\n",
            "Validation NSE = [0.0574531]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_226\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_446 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_446 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_447 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_447 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12178100 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 4s 54ms/step - loss: 0.8351 - metrics_nse: 0.0106\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7515 - metrics_nse: 0.1067\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6840 - metrics_nse: 0.1908\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6322 - metrics_nse: 0.2576\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5972 - metrics_nse: 0.2962\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5840 - metrics_nse: 0.3163\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5602 - metrics_nse: 0.3443\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5406 - metrics_nse: 0.3592\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5310 - metrics_nse: 0.3747\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5095 - metrics_nse: 0.3996\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4996 - metrics_nse: 0.4243\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4867 - metrics_nse: 0.4240\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4718 - metrics_nse: 0.4463\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4744 - metrics_nse: 0.4454\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4658 - metrics_nse: 0.4570\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4491 - metrics_nse: 0.4721\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4459 - metrics_nse: 0.4742\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4328 - metrics_nse: 0.4976\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4268 - metrics_nse: 0.5004\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4210 - metrics_nse: 0.5085\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4140 - metrics_nse: 0.5168\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4204 - metrics_nse: 0.5127\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.4044 - metrics_nse: 0.5324\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4011 - metrics_nse: 0.5387\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4030 - metrics_nse: 0.5341\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3995 - metrics_nse: 0.5397\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3913 - metrics_nse: 0.5481\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3897 - metrics_nse: 0.5543\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3829 - metrics_nse: 0.5474\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3788 - metrics_nse: 0.5591\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 49ms/step - loss: 0.3795 - metrics_nse: 0.5491\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3764 - metrics_nse: 0.5753\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3758 - metrics_nse: 0.5711\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3670 - metrics_nse: 0.5729\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3693 - metrics_nse: 0.5769\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3653 - metrics_nse: 0.5887\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3658 - metrics_nse: 0.5717\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3615 - metrics_nse: 0.5792\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3635 - metrics_nse: 0.5800\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3579 - metrics_nse: 0.5805\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3537 - metrics_nse: 0.5899\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3529 - metrics_nse: 0.5889\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3589 - metrics_nse: 0.5821\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3483 - metrics_nse: 0.5880\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3519 - metrics_nse: 0.5941\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3481 - metrics_nse: 0.5936\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3432 - metrics_nse: 0.5999\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3514 - metrics_nse: 0.5943\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3391 - metrics_nse: 0.6021\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3403 - metrics_nse: 0.6062\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.61988795]\n",
            "Validation NSE = [0.56929755]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_227\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_448 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_448 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_449 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_449 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_224 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12035000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 52ms/step - loss: 0.8908 - metrics_nse: 0.1062\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6394 - metrics_nse: 0.3508\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5655 - metrics_nse: 0.4298\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5150 - metrics_nse: 0.4827\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4600 - metrics_nse: 0.5312\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4247 - metrics_nse: 0.5762\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.3935 - metrics_nse: 0.6013\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3691 - metrics_nse: 0.6290\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3549 - metrics_nse: 0.6477\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3400 - metrics_nse: 0.6620\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3255 - metrics_nse: 0.6810\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3126 - metrics_nse: 0.6922\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3164 - metrics_nse: 0.6778\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2968 - metrics_nse: 0.7031\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2947 - metrics_nse: 0.7054\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2815 - metrics_nse: 0.7175\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2765 - metrics_nse: 0.7252\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2685 - metrics_nse: 0.7302\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2777 - metrics_nse: 0.7273\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2660 - metrics_nse: 0.7309\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2584 - metrics_nse: 0.7439\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2636 - metrics_nse: 0.7348\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2578 - metrics_nse: 0.7526\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2540 - metrics_nse: 0.7487\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2524 - metrics_nse: 0.7463\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2523 - metrics_nse: 0.7537\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2492 - metrics_nse: 0.7490\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2505 - metrics_nse: 0.7482\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2426 - metrics_nse: 0.7574\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2393 - metrics_nse: 0.7583\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2438 - metrics_nse: 0.7533\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2388 - metrics_nse: 0.7641\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2451 - metrics_nse: 0.7543\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2339 - metrics_nse: 0.7650\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2377 - metrics_nse: 0.7637\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2344 - metrics_nse: 0.7617\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2314 - metrics_nse: 0.7687\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2356 - metrics_nse: 0.7658\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2212 - metrics_nse: 0.7768\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2256 - metrics_nse: 0.7744\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2248 - metrics_nse: 0.7729\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.2296 - metrics_nse: 0.7702\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2298 - metrics_nse: 0.7690\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2283 - metrics_nse: 0.7723\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2239 - metrics_nse: 0.7770\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2284 - metrics_nse: 0.7700\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2296 - metrics_nse: 0.7684\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2285 - metrics_nse: 0.7690\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2272 - metrics_nse: 0.7722\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2186 - metrics_nse: 0.7800\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.79217017]\n",
            "Validation NSE = [0.78599113]\n",
            "--------Loading Data...........................................................\n",
            "86 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_228\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_450 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_450 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_451 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_451 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12390700 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 4s 49ms/step - loss: 0.9865 - metrics_nse: -0.0052\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8304 - metrics_nse: 0.1561\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7250 - metrics_nse: 0.2625\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6326 - metrics_nse: 0.3567\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5701 - metrics_nse: 0.4207\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5295 - metrics_nse: 0.4606\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4904 - metrics_nse: 0.5019\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4455 - metrics_nse: 0.5445\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4157 - metrics_nse: 0.5751\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3709 - metrics_nse: 0.6192\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3373 - metrics_nse: 0.6577\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3129 - metrics_nse: 0.6793\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3014 - metrics_nse: 0.6945\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2885 - metrics_nse: 0.7061\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2754 - metrics_nse: 0.7181\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2606 - metrics_nse: 0.7336\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2504 - metrics_nse: 0.7437\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2436 - metrics_nse: 0.7527\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2339 - metrics_nse: 0.7624\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2326 - metrics_nse: 0.7651\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2243 - metrics_nse: 0.7713\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2229 - metrics_nse: 0.7722\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2197 - metrics_nse: 0.7764\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2066 - metrics_nse: 0.7897\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.1968 - metrics_nse: 0.7998\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1974 - metrics_nse: 0.7995\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1881 - metrics_nse: 0.8084\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 49ms/step - loss: 0.1945 - metrics_nse: 0.8050\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1881 - metrics_nse: 0.8086\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1827 - metrics_nse: 0.8146\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1756 - metrics_nse: 0.8209\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1751 - metrics_nse: 0.8210\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1660 - metrics_nse: 0.8307\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1634 - metrics_nse: 0.8313\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1567 - metrics_nse: 0.8407\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1535 - metrics_nse: 0.8454\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1511 - metrics_nse: 0.8469\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1453 - metrics_nse: 0.8530\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1411 - metrics_nse: 0.8563\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1347 - metrics_nse: 0.8632\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1362 - metrics_nse: 0.8625\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1295 - metrics_nse: 0.8681\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1302 - metrics_nse: 0.8670\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1217 - metrics_nse: 0.8757\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1258 - metrics_nse: 0.8732\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1258 - metrics_nse: 0.8714\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1196 - metrics_nse: 0.8783\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1182 - metrics_nse: 0.8795\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1110 - metrics_nse: 0.8870\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1136 - metrics_nse: 0.8845\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.9106386]\n",
            "Validation NSE = [0.78192997]\n",
            "--------Loading Data...........................................................\n",
            "365 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_229\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_452 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_452 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_453 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_453 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12025000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 47ms/step - loss: 0.7637 - metrics_nse: 0.2685\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6025 - metrics_nse: 0.4171\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5344 - metrics_nse: 0.4987\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.4887 - metrics_nse: 0.5339\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4482 - metrics_nse: 0.5729\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4225 - metrics_nse: 0.6027\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4120 - metrics_nse: 0.6120\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3944 - metrics_nse: 0.6419\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3824 - metrics_nse: 0.6495\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3605 - metrics_nse: 0.6541\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3524 - metrics_nse: 0.6522\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3444 - metrics_nse: 0.6949\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3334 - metrics_nse: 0.6894\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3302 - metrics_nse: 0.6912\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3225 - metrics_nse: 0.7001\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3148 - metrics_nse: 0.6892\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3102 - metrics_nse: 0.7041\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3025 - metrics_nse: 0.7134\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3035 - metrics_nse: 0.7205\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2981 - metrics_nse: 0.7312\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2954 - metrics_nse: 0.7083\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2955 - metrics_nse: 0.7201\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3000 - metrics_nse: 0.7291\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2876 - metrics_nse: 0.7173\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2874 - metrics_nse: 0.7191\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2778 - metrics_nse: 0.7287\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2761 - metrics_nse: 0.7348\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2794 - metrics_nse: 0.7361\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2849 - metrics_nse: 0.7320\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2738 - metrics_nse: 0.7500\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2690 - metrics_nse: 0.7347\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2670 - metrics_nse: 0.7434\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2654 - metrics_nse: 0.7525\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2606 - metrics_nse: 0.7449\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2596 - metrics_nse: 0.7606\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2593 - metrics_nse: 0.7634\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2496 - metrics_nse: 0.7690\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2506 - metrics_nse: 0.7526\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.2438 - metrics_nse: 0.7756\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2453 - metrics_nse: 0.7615\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2469 - metrics_nse: 0.7565\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.2417 - metrics_nse: 0.7814\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2398 - metrics_nse: 0.7717\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2346 - metrics_nse: 0.7815\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.2369 - metrics_nse: 0.7774\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2442 - metrics_nse: 0.7590\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2331 - metrics_nse: 0.7840\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2371 - metrics_nse: 0.7823\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2299 - metrics_nse: 0.7683\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2259 - metrics_nse: 0.7865\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.7871568]\n",
            "Validation NSE = [0.7105072]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_230\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_454 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_454 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_455 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_455 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12010000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 50ms/step - loss: 0.8312 - metrics_nse: 0.1901\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6438 - metrics_nse: 0.3748\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5733 - metrics_nse: 0.4463\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5295 - metrics_nse: 0.4817\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4887 - metrics_nse: 0.5269\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4712 - metrics_nse: 0.5468\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.4522 - metrics_nse: 0.5595\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4326 - metrics_nse: 0.5813\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4207 - metrics_nse: 0.5974\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4035 - metrics_nse: 0.6078\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3964 - metrics_nse: 0.6134\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3892 - metrics_nse: 0.6215\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3812 - metrics_nse: 0.6316\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3733 - metrics_nse: 0.6449\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3755 - metrics_nse: 0.6386\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3652 - metrics_nse: 0.6495\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3579 - metrics_nse: 0.6609\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3607 - metrics_nse: 0.6509\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3553 - metrics_nse: 0.6582\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3568 - metrics_nse: 0.6545\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3504 - metrics_nse: 0.6654\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3542 - metrics_nse: 0.6598\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3472 - metrics_nse: 0.6770\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3468 - metrics_nse: 0.6690\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3473 - metrics_nse: 0.6720\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3536 - metrics_nse: 0.6561\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3357 - metrics_nse: 0.6743\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3444 - metrics_nse: 0.6703\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3400 - metrics_nse: 0.6779\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3405 - metrics_nse: 0.6820\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3453 - metrics_nse: 0.6667\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3433 - metrics_nse: 0.6683\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3403 - metrics_nse: 0.6745\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3315 - metrics_nse: 0.6816\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3336 - metrics_nse: 0.6819\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3312 - metrics_nse: 0.6841\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3374 - metrics_nse: 0.6706\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3300 - metrics_nse: 0.6755\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3300 - metrics_nse: 0.6852\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3302 - metrics_nse: 0.6884\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3299 - metrics_nse: 0.6858\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3217 - metrics_nse: 0.6873\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3263 - metrics_nse: 0.6952\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3223 - metrics_nse: 0.6851\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3242 - metrics_nse: 0.6891\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3190 - metrics_nse: 0.6907\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3166 - metrics_nse: 0.6917\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3305 - metrics_nse: 0.6746\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3208 - metrics_nse: 0.6950\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3145 - metrics_nse: 0.7056\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.70192915]\n",
            "Validation NSE = [0.69874656]\n",
            "--------Loading Data...........................................................\n",
            "1492 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_231\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_456 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_456 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_457 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_457 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_228 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12144000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 52ms/step - loss: 1.3219 - metrics_nse: -0.3189\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.9977 - metrics_nse: 0.0322\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9431 - metrics_nse: 0.0874\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9259 - metrics_nse: 0.1024\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9170 - metrics_nse: 0.1176\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9181 - metrics_nse: 0.1150\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9120 - metrics_nse: 0.1204\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9079 - metrics_nse: 0.1244\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9041 - metrics_nse: 0.1313\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.8992 - metrics_nse: 0.1352\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.8982 - metrics_nse: 0.1340\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8983 - metrics_nse: 0.1354\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8919 - metrics_nse: 0.1453\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8919 - metrics_nse: 0.1422\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8874 - metrics_nse: 0.1400\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8902 - metrics_nse: 0.1391\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8871 - metrics_nse: 0.1425\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8833 - metrics_nse: 0.1522\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8819 - metrics_nse: 0.1478\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8789 - metrics_nse: 0.1553\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8772 - metrics_nse: 0.1524\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8745 - metrics_nse: 0.1535\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8758 - metrics_nse: 0.1589\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8725 - metrics_nse: 0.1556\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8700 - metrics_nse: 0.1645\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8697 - metrics_nse: 0.1600\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.8681 - metrics_nse: 0.1599\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8670 - metrics_nse: 0.1622\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8614 - metrics_nse: 0.1653\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8655 - metrics_nse: 0.1675\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8640 - metrics_nse: 0.1779\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.8631 - metrics_nse: 0.1655\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8568 - metrics_nse: 0.1743\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8561 - metrics_nse: 0.1737\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8529 - metrics_nse: 0.1708\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8548 - metrics_nse: 0.1795\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8495 - metrics_nse: 0.1811\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8500 - metrics_nse: 0.1775\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8473 - metrics_nse: 0.1801\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8454 - metrics_nse: 0.1841\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8403 - metrics_nse: 0.1909\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8366 - metrics_nse: 0.1913\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.8347 - metrics_nse: 0.1896\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8328 - metrics_nse: 0.1970\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8267 - metrics_nse: 0.2027\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8202 - metrics_nse: 0.2149\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8140 - metrics_nse: 0.2126\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.8061 - metrics_nse: 0.2177\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8006 - metrics_nse: 0.2282\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7964 - metrics_nse: 0.2395\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.24207771]\n",
            "Validation NSE = [0.09003365]\n",
            "--------Loading Data...........................................................\n",
            "1363 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_232\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_458 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_458 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_459 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_459 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_229 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14303200 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 51ms/step - loss: 0.9302 - metrics_nse: 0.1116\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8601 - metrics_nse: 0.1748\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8388 - metrics_nse: 0.1966\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8308 - metrics_nse: 0.2086\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8232 - metrics_nse: 0.2145\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.8253 - metrics_nse: 0.2153\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8226 - metrics_nse: 0.2098\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8152 - metrics_nse: 0.2173\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8092 - metrics_nse: 0.2268\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8062 - metrics_nse: 0.2269\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8000 - metrics_nse: 0.2335\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7975 - metrics_nse: 0.2388\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7892 - metrics_nse: 0.2470\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7867 - metrics_nse: 0.2451\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7742 - metrics_nse: 0.2581\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7793 - metrics_nse: 0.2594\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7701 - metrics_nse: 0.2670\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7659 - metrics_nse: 0.2724\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7617 - metrics_nse: 0.2702\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7632 - metrics_nse: 0.2696\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7575 - metrics_nse: 0.2814\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7561 - metrics_nse: 0.2776\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7485 - metrics_nse: 0.2888\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7563 - metrics_nse: 0.2863\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7521 - metrics_nse: 0.2782\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7557 - metrics_nse: 0.2773\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7517 - metrics_nse: 0.2821\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7396 - metrics_nse: 0.2944\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7406 - metrics_nse: 0.2948\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7396 - metrics_nse: 0.2942\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7355 - metrics_nse: 0.2948\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7386 - metrics_nse: 0.2889\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7321 - metrics_nse: 0.3016\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7280 - metrics_nse: 0.3062\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7348 - metrics_nse: 0.2921\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7291 - metrics_nse: 0.3016\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7505 - metrics_nse: 0.2785\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7336 - metrics_nse: 0.2934\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7316 - metrics_nse: 0.3024\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7350 - metrics_nse: 0.2975\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7145 - metrics_nse: 0.3191\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7160 - metrics_nse: 0.3141\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7055 - metrics_nse: 0.3289\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7092 - metrics_nse: 0.3225\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7043 - metrics_nse: 0.3207\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7108 - metrics_nse: 0.3161\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6914 - metrics_nse: 0.3377\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6907 - metrics_nse: 0.3326\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6789 - metrics_nse: 0.3489\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6763 - metrics_nse: 0.3569\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.3646567]\n",
            "Validation NSE = [0.1121313]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_233\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_460 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_460 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_461 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_461 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_230 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 13235000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 49ms/step - loss: 0.9935 - metrics_nse: 0.0282\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8034 - metrics_nse: 0.2136\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7370 - metrics_nse: 0.2754\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6704 - metrics_nse: 0.3411\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6117 - metrics_nse: 0.4006\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5569 - metrics_nse: 0.4503\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5059 - metrics_nse: 0.5055\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4743 - metrics_nse: 0.5341\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4328 - metrics_nse: 0.5763\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3927 - metrics_nse: 0.6172\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.3436 - metrics_nse: 0.6635\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3039 - metrics_nse: 0.7018\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3047 - metrics_nse: 0.7020\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2836 - metrics_nse: 0.7186\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2796 - metrics_nse: 0.7244\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2733 - metrics_nse: 0.7322\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2583 - metrics_nse: 0.7459\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2573 - metrics_nse: 0.7450\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2498 - metrics_nse: 0.7503\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2452 - metrics_nse: 0.7581\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2425 - metrics_nse: 0.7608\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2308 - metrics_nse: 0.7749\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2105 - metrics_nse: 0.7936\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2094 - metrics_nse: 0.7951\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2028 - metrics_nse: 0.7986\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1918 - metrics_nse: 0.8096\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1894 - metrics_nse: 0.8141\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1809 - metrics_nse: 0.8200\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1677 - metrics_nse: 0.8342\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1687 - metrics_nse: 0.8330\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1712 - metrics_nse: 0.8317\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1595 - metrics_nse: 0.8391\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1604 - metrics_nse: 0.8398\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1517 - metrics_nse: 0.8503\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1499 - metrics_nse: 0.8521\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1375 - metrics_nse: 0.8636\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1247 - metrics_nse: 0.8775\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1218 - metrics_nse: 0.8810\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1136 - metrics_nse: 0.8871\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1145 - metrics_nse: 0.8878\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1144 - metrics_nse: 0.8870\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1109 - metrics_nse: 0.8886\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1018 - metrics_nse: 0.8994\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1006 - metrics_nse: 0.9014\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0978 - metrics_nse: 0.9032\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1021 - metrics_nse: 0.8993\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0970 - metrics_nse: 0.9024\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0937 - metrics_nse: 0.9075\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0844 - metrics_nse: 0.9167\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0872 - metrics_nse: 0.9139\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.94221556]\n",
            "Validation NSE = [0.57333565]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_234\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_462 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_462 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_463 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_463 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_231 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14154500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 51ms/step - loss: 1.0281 - metrics_nse: -0.0221\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7384 - metrics_nse: 0.2882\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6971 - metrics_nse: 0.3276\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6362 - metrics_nse: 0.4060\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6115 - metrics_nse: 0.4184\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5910 - metrics_nse: 0.4350\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5677 - metrics_nse: 0.4636\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5552 - metrics_nse: 0.4745\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5361 - metrics_nse: 0.4941\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5272 - metrics_nse: 0.5010\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5045 - metrics_nse: 0.5199\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4887 - metrics_nse: 0.5348\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4766 - metrics_nse: 0.5445\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4666 - metrics_nse: 0.5515\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4579 - metrics_nse: 0.5634\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4597 - metrics_nse: 0.5749\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4398 - metrics_nse: 0.5769\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4383 - metrics_nse: 0.5881\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4315 - metrics_nse: 0.5919\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4247 - metrics_nse: 0.5990\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4286 - metrics_nse: 0.5942\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4215 - metrics_nse: 0.5955\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4177 - metrics_nse: 0.6060\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4194 - metrics_nse: 0.6036\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4166 - metrics_nse: 0.6104\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4049 - metrics_nse: 0.6262\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4064 - metrics_nse: 0.6121\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4005 - metrics_nse: 0.6216\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4040 - metrics_nse: 0.6184\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4083 - metrics_nse: 0.6133\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4040 - metrics_nse: 0.6210\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3942 - metrics_nse: 0.6199\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.3955 - metrics_nse: 0.6239\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3914 - metrics_nse: 0.6269\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3913 - metrics_nse: 0.6241\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3902 - metrics_nse: 0.6338\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3847 - metrics_nse: 0.6385\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3900 - metrics_nse: 0.6275\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3862 - metrics_nse: 0.6360\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3766 - metrics_nse: 0.6379\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3772 - metrics_nse: 0.6421\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3726 - metrics_nse: 0.6508\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3790 - metrics_nse: 0.6450\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3592 - metrics_nse: 0.6712\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3689 - metrics_nse: 0.6478\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3637 - metrics_nse: 0.6591\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3617 - metrics_nse: 0.6498\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3560 - metrics_nse: 0.6629\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3590 - metrics_nse: 0.6717\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3653 - metrics_nse: 0.6559\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.6721315]\n",
            "Validation NSE = [0.67333025]\n",
            "--------Loading Data...........................................................\n",
            "2100 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_235\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_464 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_464 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_465 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_465 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_232 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14308990 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 50ms/step - loss: 0.9961 - metrics_nse: 0.0462\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9588 - metrics_nse: 0.0863\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9403 - metrics_nse: 0.1073\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9385 - metrics_nse: 0.1189\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9377 - metrics_nse: 0.1045\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 0.9335 - metrics_nse: 0.1120\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9299 - metrics_nse: 0.1167\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.9294 - metrics_nse: 0.1229\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9295 - metrics_nse: 0.1136\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.9228 - metrics_nse: 0.1319\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.9257 - metrics_nse: 0.1140\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.9249 - metrics_nse: 0.1268\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9237 - metrics_nse: 0.1332\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9248 - metrics_nse: 0.1167\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9205 - metrics_nse: 0.1237\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9193 - metrics_nse: 0.1322\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.9211 - metrics_nse: 0.1318\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9181 - metrics_nse: 0.1289\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9188 - metrics_nse: 0.1210\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9174 - metrics_nse: 0.1319\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9186 - metrics_nse: 0.1304\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.9191 - metrics_nse: 0.1310\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9185 - metrics_nse: 0.1244\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9162 - metrics_nse: 0.1274\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9145 - metrics_nse: 0.1318\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9184 - metrics_nse: 0.1337\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9143 - metrics_nse: 0.1352\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.9131 - metrics_nse: 0.1376\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9135 - metrics_nse: 0.1363\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9115 - metrics_nse: 0.1442\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9130 - metrics_nse: 0.1454\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9077 - metrics_nse: 0.1465\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.9089 - metrics_nse: 0.1432\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.9076 - metrics_nse: 0.1380\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.9078 - metrics_nse: 0.1431\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9044 - metrics_nse: 0.1583\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9060 - metrics_nse: 0.1520\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9040 - metrics_nse: 0.1484\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8990 - metrics_nse: 0.1442\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.9036 - metrics_nse: 0.1493\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8969 - metrics_nse: 0.1528\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8897 - metrics_nse: 0.1645\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8815 - metrics_nse: 0.1706\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8752 - metrics_nse: 0.1744\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8604 - metrics_nse: 0.1933\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8719 - metrics_nse: 0.1729\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8971 - metrics_nse: 0.1300\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8910 - metrics_nse: 0.1597\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8708 - metrics_nse: 0.1761\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.8553 - metrics_nse: 0.1934\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.19387275]\n",
            "Validation NSE = [0.16042316]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_236\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_466 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_466 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_467 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_467 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_233 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12147500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 52ms/step - loss: 0.8912 - metrics_nse: 0.1046\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7854 - metrics_nse: 0.2082\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7452 - metrics_nse: 0.2499\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7124 - metrics_nse: 0.2938\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6746 - metrics_nse: 0.3295\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.6472 - metrics_nse: 0.3531\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6248 - metrics_nse: 0.3772\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.6200 - metrics_nse: 0.3842\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.5970 - metrics_nse: 0.4047\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5857 - metrics_nse: 0.4079\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5773 - metrics_nse: 0.4180\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5754 - metrics_nse: 0.4277\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5602 - metrics_nse: 0.4351\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5556 - metrics_nse: 0.4475\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5537 - metrics_nse: 0.4438\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5502 - metrics_nse: 0.4559\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5438 - metrics_nse: 0.4618\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.5292 - metrics_nse: 0.4742\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5315 - metrics_nse: 0.4764\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5263 - metrics_nse: 0.4747\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5174 - metrics_nse: 0.4843\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5318 - metrics_nse: 0.4633\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5266 - metrics_nse: 0.4754\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 49ms/step - loss: 0.5191 - metrics_nse: 0.4775\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5210 - metrics_nse: 0.4956\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5139 - metrics_nse: 0.4873\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5136 - metrics_nse: 0.4863\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5141 - metrics_nse: 0.4977\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5155 - metrics_nse: 0.4871\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5091 - metrics_nse: 0.4915\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5071 - metrics_nse: 0.4965\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5050 - metrics_nse: 0.5026\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5067 - metrics_nse: 0.4959\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5008 - metrics_nse: 0.4977\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5011 - metrics_nse: 0.5010\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4974 - metrics_nse: 0.4998\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.5021 - metrics_nse: 0.5043\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4945 - metrics_nse: 0.5022\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4948 - metrics_nse: 0.5079\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5010 - metrics_nse: 0.4953\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4963 - metrics_nse: 0.4957\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5004 - metrics_nse: 0.5025\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4887 - metrics_nse: 0.5114\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4901 - metrics_nse: 0.5149\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4998 - metrics_nse: 0.5082\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4876 - metrics_nse: 0.5112\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4886 - metrics_nse: 0.5139\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4890 - metrics_nse: 0.5060\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4847 - metrics_nse: 0.5110\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4788 - metrics_nse: 0.5131\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.52929395]\n",
            "Validation NSE = [0.42838156]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_237\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_468 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_468 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_469 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_469 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_234 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12447390 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 4s 52ms/step - loss: 0.8793 - metrics_nse: 0.1277\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8070 - metrics_nse: 0.1997\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.7515 - metrics_nse: 0.2582\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.7107 - metrics_nse: 0.2959\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6687 - metrics_nse: 0.3390\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6266 - metrics_nse: 0.3785\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5724 - metrics_nse: 0.4343\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5018 - metrics_nse: 0.5044\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4328 - metrics_nse: 0.5678\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3587 - metrics_nse: 0.6387\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3243 - metrics_nse: 0.6777\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2976 - metrics_nse: 0.7029\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2852 - metrics_nse: 0.7167\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2672 - metrics_nse: 0.7357\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2618 - metrics_nse: 0.7430\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2507 - metrics_nse: 0.7514\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2451 - metrics_nse: 0.7588\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2459 - metrics_nse: 0.7539\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2276 - metrics_nse: 0.7720\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2253 - metrics_nse: 0.7738\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2232 - metrics_nse: 0.7801\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2156 - metrics_nse: 0.7821\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2039 - metrics_nse: 0.7960\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1950 - metrics_nse: 0.8084\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1884 - metrics_nse: 0.8101\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1899 - metrics_nse: 0.8087\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1885 - metrics_nse: 0.8134\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1768 - metrics_nse: 0.8247\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1713 - metrics_nse: 0.8281\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1615 - metrics_nse: 0.8406\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1619 - metrics_nse: 0.8403\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1606 - metrics_nse: 0.8424\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1563 - metrics_nse: 0.8459\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1499 - metrics_nse: 0.8523\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1538 - metrics_nse: 0.8478\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1403 - metrics_nse: 0.8616\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1412 - metrics_nse: 0.8593\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1429 - metrics_nse: 0.8587\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1394 - metrics_nse: 0.8614\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1406 - metrics_nse: 0.8610\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1335 - metrics_nse: 0.8683\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1284 - metrics_nse: 0.8734\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1259 - metrics_nse: 0.8759\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1247 - metrics_nse: 0.8757\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1276 - metrics_nse: 0.8733\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1283 - metrics_nse: 0.8740\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1282 - metrics_nse: 0.8724\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1173 - metrics_nse: 0.8852\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1187 - metrics_nse: 0.8819\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1176 - metrics_nse: 0.8829\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.9170143]\n",
            "Validation NSE = [0.675094]\n",
            "--------Loading Data...........................................................\n",
            "84 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_238\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_470 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_470 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_471 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_471 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_235 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 13337000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 50ms/step - loss: 0.7828 - metrics_nse: 0.2144\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.6449 - metrics_nse: 0.3533\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5431 - metrics_nse: 0.4573\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4842 - metrics_nse: 0.5136\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4411 - metrics_nse: 0.5569\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3880 - metrics_nse: 0.6101\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3334 - metrics_nse: 0.6647\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2753 - metrics_nse: 0.7246\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2341 - metrics_nse: 0.7657\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2099 - metrics_nse: 0.7892\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1906 - metrics_nse: 0.8082\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1843 - metrics_nse: 0.8154\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1725 - metrics_nse: 0.8273\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1601 - metrics_nse: 0.8399\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1495 - metrics_nse: 0.8503\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1439 - metrics_nse: 0.8556\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1353 - metrics_nse: 0.8634\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1236 - metrics_nse: 0.8760\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1222 - metrics_nse: 0.8771\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1154 - metrics_nse: 0.8836\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1134 - metrics_nse: 0.8864\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1054 - metrics_nse: 0.8943\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0977 - metrics_nse: 0.9014\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.0958 - metrics_nse: 0.9036\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0939 - metrics_nse: 0.9062\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0894 - metrics_nse: 0.9102\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0843 - metrics_nse: 0.9155\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0885 - metrics_nse: 0.9112\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0845 - metrics_nse: 0.9143\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0765 - metrics_nse: 0.9230\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0778 - metrics_nse: 0.9220\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0787 - metrics_nse: 0.9208\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0748 - metrics_nse: 0.9245\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0697 - metrics_nse: 0.9298\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0717 - metrics_nse: 0.9286\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0721 - metrics_nse: 0.9278\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0703 - metrics_nse: 0.9293\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0666 - metrics_nse: 0.9331\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0663 - metrics_nse: 0.9334\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0672 - metrics_nse: 0.9325\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0637 - metrics_nse: 0.9362\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0633 - metrics_nse: 0.9360\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0619 - metrics_nse: 0.9377\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0585 - metrics_nse: 0.9410\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0589 - metrics_nse: 0.9410\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0579 - metrics_nse: 0.9418\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0580 - metrics_nse: 0.9418\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0571 - metrics_nse: 0.9426\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0537 - metrics_nse: 0.9459\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0522 - metrics_nse: 0.9475\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.95975316]\n",
            "Validation NSE = [0.8326192]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_239\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_472 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_472 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_473 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_473 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_236 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12115500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 52ms/step - loss: 0.9746 - metrics_nse: 0.0303\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.8557 - metrics_nse: 0.1610\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7696 - metrics_nse: 0.2420\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6892 - metrics_nse: 0.3230\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6477 - metrics_nse: 0.3797\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6111 - metrics_nse: 0.4106\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5976 - metrics_nse: 0.4209\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.5798 - metrics_nse: 0.4348\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5587 - metrics_nse: 0.4598\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5558 - metrics_nse: 0.4624\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5307 - metrics_nse: 0.4841\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5218 - metrics_nse: 0.4946\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5254 - metrics_nse: 0.4939\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5097 - metrics_nse: 0.5087\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5044 - metrics_nse: 0.5068\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4999 - metrics_nse: 0.5025\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4968 - metrics_nse: 0.5222\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4759 - metrics_nse: 0.5530\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4712 - metrics_nse: 0.5430\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4690 - metrics_nse: 0.5502\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4700 - metrics_nse: 0.5448\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4617 - metrics_nse: 0.5518\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4500 - metrics_nse: 0.5663\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4501 - metrics_nse: 0.5697\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4461 - metrics_nse: 0.5729\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4323 - metrics_nse: 0.5724\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4292 - metrics_nse: 0.5800\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4227 - metrics_nse: 0.5821\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4331 - metrics_nse: 0.5819\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4183 - metrics_nse: 0.5993\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4167 - metrics_nse: 0.6012\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4052 - metrics_nse: 0.6090\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4101 - metrics_nse: 0.6025\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4128 - metrics_nse: 0.5979\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4053 - metrics_nse: 0.6155\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4106 - metrics_nse: 0.5999\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4019 - metrics_nse: 0.6114\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4036 - metrics_nse: 0.6069\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3926 - metrics_nse: 0.6204\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3906 - metrics_nse: 0.6219\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3931 - metrics_nse: 0.6131\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3902 - metrics_nse: 0.6295\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3894 - metrics_nse: 0.6296\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3790 - metrics_nse: 0.6198\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3804 - metrics_nse: 0.6276\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3811 - metrics_nse: 0.6294\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3756 - metrics_nse: 0.6475\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3720 - metrics_nse: 0.6415\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3701 - metrics_nse: 0.6477\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3665 - metrics_nse: 0.6514\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.6604463]\n",
            "Validation NSE = [0.5387074]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_240\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_474 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_474 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_475 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_475 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_237 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14305500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 48ms/step - loss: 0.7913 - metrics_nse: 0.2068\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5056 - metrics_nse: 0.4936\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4671 - metrics_nse: 0.5278\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4301 - metrics_nse: 0.5660\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4101 - metrics_nse: 0.5877\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3895 - metrics_nse: 0.6059\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3652 - metrics_nse: 0.6312\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3567 - metrics_nse: 0.6365\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3447 - metrics_nse: 0.6506\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3381 - metrics_nse: 0.6573\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3319 - metrics_nse: 0.6626\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3208 - metrics_nse: 0.6747\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3140 - metrics_nse: 0.6804\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3074 - metrics_nse: 0.6866\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3030 - metrics_nse: 0.6937\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2997 - metrics_nse: 0.6968\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2933 - metrics_nse: 0.7042\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2732 - metrics_nse: 0.7243\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2752 - metrics_nse: 0.7210\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2773 - metrics_nse: 0.7233\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2674 - metrics_nse: 0.7279\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2695 - metrics_nse: 0.7270\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2611 - metrics_nse: 0.7363\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2586 - metrics_nse: 0.7399\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2685 - metrics_nse: 0.7300\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2634 - metrics_nse: 0.7379\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2564 - metrics_nse: 0.7413\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2606 - metrics_nse: 0.7372\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2457 - metrics_nse: 0.7529\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2522 - metrics_nse: 0.7445\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2514 - metrics_nse: 0.7488\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2450 - metrics_nse: 0.7512\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2395 - metrics_nse: 0.7588\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2430 - metrics_nse: 0.7558\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2465 - metrics_nse: 0.7505\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2363 - metrics_nse: 0.7627\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2412 - metrics_nse: 0.7555\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2440 - metrics_nse: 0.7552\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2319 - metrics_nse: 0.7659\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2413 - metrics_nse: 0.7579\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2398 - metrics_nse: 0.7557\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2377 - metrics_nse: 0.7624\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2362 - metrics_nse: 0.7592\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2388 - metrics_nse: 0.7594\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2281 - metrics_nse: 0.7698\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2303 - metrics_nse: 0.7638\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2277 - metrics_nse: 0.7691\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2283 - metrics_nse: 0.7682\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2258 - metrics_nse: 0.7714\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2314 - metrics_nse: 0.7660\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.78702426]\n",
            "Validation NSE = [0.7151657]\n",
            "--------Loading Data...........................................................\n",
            "428 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_241\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_476 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_476 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_477 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_477 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_238 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12141300 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 46ms/step - loss: 0.9237 - metrics_nse: 0.0490\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7966 - metrics_nse: 0.1958\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7093 - metrics_nse: 0.2861\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6400 - metrics_nse: 0.3421\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5906 - metrics_nse: 0.4156\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5723 - metrics_nse: 0.4189\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5487 - metrics_nse: 0.4486\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5354 - metrics_nse: 0.4706\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5013 - metrics_nse: 0.4931\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4923 - metrics_nse: 0.5071\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4681 - metrics_nse: 0.5209\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.4570 - metrics_nse: 0.5457\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4452 - metrics_nse: 0.5520\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4337 - metrics_nse: 0.5587\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.4199 - metrics_nse: 0.5816\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4079 - metrics_nse: 0.5870\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3939 - metrics_nse: 0.5949\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3828 - metrics_nse: 0.6066\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3841 - metrics_nse: 0.6012\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3799 - metrics_nse: 0.6137\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3775 - metrics_nse: 0.6285\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3681 - metrics_nse: 0.6237\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3575 - metrics_nse: 0.6371\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3610 - metrics_nse: 0.6312\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3538 - metrics_nse: 0.6455\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3462 - metrics_nse: 0.6447\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3469 - metrics_nse: 0.6510\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3480 - metrics_nse: 0.6678\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3402 - metrics_nse: 0.6462\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3324 - metrics_nse: 0.6513\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3329 - metrics_nse: 0.6677\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3360 - metrics_nse: 0.6650\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3432 - metrics_nse: 0.6551\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3367 - metrics_nse: 0.6706\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 43ms/step - loss: 0.3294 - metrics_nse: 0.6744\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3365 - metrics_nse: 0.6771\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3313 - metrics_nse: 0.6665\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3220 - metrics_nse: 0.6598\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3249 - metrics_nse: 0.6535\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3301 - metrics_nse: 0.6703\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3218 - metrics_nse: 0.6792\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3130 - metrics_nse: 0.6871\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3168 - metrics_nse: 0.6861\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3136 - metrics_nse: 0.6875\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3198 - metrics_nse: 0.6676\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3166 - metrics_nse: 0.6792\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3161 - metrics_nse: 0.6713\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3181 - metrics_nse: 0.6693\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3146 - metrics_nse: 0.6790\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3176 - metrics_nse: 0.6799\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.7067209]\n",
            "Validation NSE = [0.5967512]\n",
            "--------Loading Data...........................................................\n",
            "14 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_242\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_478 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_478 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_479 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_479 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_239 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12020000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 51ms/step - loss: 0.8847 - metrics_nse: 0.1079\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6739 - metrics_nse: 0.3518\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.5939 - metrics_nse: 0.4161\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5620 - metrics_nse: 0.4635\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.5266 - metrics_nse: 0.5011\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5121 - metrics_nse: 0.5040\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4877 - metrics_nse: 0.5426\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.4842 - metrics_nse: 0.5284\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4660 - metrics_nse: 0.5538\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4531 - metrics_nse: 0.5619\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4432 - metrics_nse: 0.5706\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4420 - metrics_nse: 0.5815\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4284 - metrics_nse: 0.5922\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4255 - metrics_nse: 0.5968\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4148 - metrics_nse: 0.5965\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4073 - metrics_nse: 0.6087\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4060 - metrics_nse: 0.6018\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3998 - metrics_nse: 0.6118\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4005 - metrics_nse: 0.6141\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3943 - metrics_nse: 0.6250\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3923 - metrics_nse: 0.6177\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3896 - metrics_nse: 0.6226\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3839 - metrics_nse: 0.6257\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3749 - metrics_nse: 0.6519\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3721 - metrics_nse: 0.6390\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3847 - metrics_nse: 0.6370\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3622 - metrics_nse: 0.6508\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3670 - metrics_nse: 0.6460\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3656 - metrics_nse: 0.6554\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3633 - metrics_nse: 0.6500\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3610 - metrics_nse: 0.6502\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3578 - metrics_nse: 0.6589\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3492 - metrics_nse: 0.6657\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.3618 - metrics_nse: 0.6593\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3539 - metrics_nse: 0.6570\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3542 - metrics_nse: 0.6517\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3464 - metrics_nse: 0.6640\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3451 - metrics_nse: 0.6789\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3517 - metrics_nse: 0.6568\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3404 - metrics_nse: 0.6655\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3487 - metrics_nse: 0.6678\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3345 - metrics_nse: 0.6800\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3431 - metrics_nse: 0.6625\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3371 - metrics_nse: 0.6755\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3410 - metrics_nse: 0.6548\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3384 - metrics_nse: 0.6788\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3472 - metrics_nse: 0.6683\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3368 - metrics_nse: 0.6786\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3374 - metrics_nse: 0.6708\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3304 - metrics_nse: 0.6818\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.68370295]\n",
            "Validation NSE = [0.4499697]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_243\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_480 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_480 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_481 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_481 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_240 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 13340000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 50ms/step - loss: 0.8056 - metrics_nse: 0.1865\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6634 - metrics_nse: 0.3311\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5437 - metrics_nse: 0.4519\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4790 - metrics_nse: 0.5155\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4475 - metrics_nse: 0.5481\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3918 - metrics_nse: 0.6043\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3331 - metrics_nse: 0.6637\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2831 - metrics_nse: 0.7145\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2351 - metrics_nse: 0.7621\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1950 - metrics_nse: 0.8033\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1613 - metrics_nse: 0.8371\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1525 - metrics_nse: 0.8466\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1423 - metrics_nse: 0.8570\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1387 - metrics_nse: 0.8605\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1316 - metrics_nse: 0.8680\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1299 - metrics_nse: 0.8687\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1246 - metrics_nse: 0.8744\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1199 - metrics_nse: 0.8785\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1128 - metrics_nse: 0.8864\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1089 - metrics_nse: 0.8902\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1041 - metrics_nse: 0.8952\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1013 - metrics_nse: 0.8978\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0964 - metrics_nse: 0.9016\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0925 - metrics_nse: 0.9065\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0880 - metrics_nse: 0.9107\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0924 - metrics_nse: 0.9064\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0902 - metrics_nse: 0.9082\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0861 - metrics_nse: 0.9123\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0831 - metrics_nse: 0.9159\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0817 - metrics_nse: 0.9156\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0775 - metrics_nse: 0.9214\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0763 - metrics_nse: 0.9231\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.0730 - metrics_nse: 0.9257\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0741 - metrics_nse: 0.9249\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0712 - metrics_nse: 0.9279\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.0738 - metrics_nse: 0.9255\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0710 - metrics_nse: 0.9283\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0688 - metrics_nse: 0.9309\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0648 - metrics_nse: 0.9347\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0643 - metrics_nse: 0.9347\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0644 - metrics_nse: 0.9346\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0643 - metrics_nse: 0.9351\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0623 - metrics_nse: 0.9373\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.0670 - metrics_nse: 0.9322\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0651 - metrics_nse: 0.9339\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0648 - metrics_nse: 0.9338\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0605 - metrics_nse: 0.9389\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.0583 - metrics_nse: 0.9410\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0569 - metrics_nse: 0.9428\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0575 - metrics_nse: 0.9409\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.9600754]\n",
            "Validation NSE = [0.8712255]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_244\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_482 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_482 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_483 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_483 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_241 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14309500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 47ms/step - loss: 1.0809 - metrics_nse: -0.0481\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8279 - metrics_nse: 0.2106\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7199 - metrics_nse: 0.3066\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6650 - metrics_nse: 0.3615\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6209 - metrics_nse: 0.4140\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5928 - metrics_nse: 0.4286\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5642 - metrics_nse: 0.4604\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5422 - metrics_nse: 0.4887\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5237 - metrics_nse: 0.4960\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5049 - metrics_nse: 0.5142\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4935 - metrics_nse: 0.5382\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4907 - metrics_nse: 0.5289\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4692 - metrics_nse: 0.5553\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4561 - metrics_nse: 0.5691\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4595 - metrics_nse: 0.5635\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4523 - metrics_nse: 0.5735\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4431 - metrics_nse: 0.5768\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4311 - metrics_nse: 0.5938\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4243 - metrics_nse: 0.5941\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4228 - metrics_nse: 0.5991\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4176 - metrics_nse: 0.6047\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4215 - metrics_nse: 0.5988\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4076 - metrics_nse: 0.6124\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.4039 - metrics_nse: 0.6136\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3974 - metrics_nse: 0.6125\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3998 - metrics_nse: 0.6231\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3952 - metrics_nse: 0.6195\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3830 - metrics_nse: 0.6334\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3849 - metrics_nse: 0.6341\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3746 - metrics_nse: 0.6381\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3793 - metrics_nse: 0.6433\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3658 - metrics_nse: 0.6490\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3636 - metrics_nse: 0.6526\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3664 - metrics_nse: 0.6481\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3656 - metrics_nse: 0.6474\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3652 - metrics_nse: 0.6544\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3649 - metrics_nse: 0.6512\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3553 - metrics_nse: 0.6553\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3565 - metrics_nse: 0.6625\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3423 - metrics_nse: 0.6845\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3514 - metrics_nse: 0.6616\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3476 - metrics_nse: 0.6623\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3533 - metrics_nse: 0.6680\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3495 - metrics_nse: 0.6657\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3480 - metrics_nse: 0.6658\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3370 - metrics_nse: 0.6846\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3458 - metrics_nse: 0.6709\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3444 - metrics_nse: 0.6741\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3372 - metrics_nse: 0.6918\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3349 - metrics_nse: 0.6936\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.6967282]\n",
            "Validation NSE = [0.69028366]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_245\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_484 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_484 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_485 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_485 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_242 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 13011500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 47ms/step - loss: 1.0758 - metrics_nse: -0.0549\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.8758 - metrics_nse: 0.1395\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.7814 - metrics_nse: 0.2349\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7050 - metrics_nse: 0.3109\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6400 - metrics_nse: 0.3737\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5687 - metrics_nse: 0.4419\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4893 - metrics_nse: 0.5188\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4192 - metrics_nse: 0.5912\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3430 - metrics_nse: 0.6661\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2762 - metrics_nse: 0.7298\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2445 - metrics_nse: 0.7606\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2209 - metrics_nse: 0.7845\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.2091 - metrics_nse: 0.7960\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1932 - metrics_nse: 0.8121\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.1803 - metrics_nse: 0.8229\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1707 - metrics_nse: 0.8341\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1776 - metrics_nse: 0.8254\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1614 - metrics_nse: 0.8431\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1535 - metrics_nse: 0.8490\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1498 - metrics_nse: 0.8521\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1512 - metrics_nse: 0.8514\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1468 - metrics_nse: 0.8557\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.1439 - metrics_nse: 0.8576\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1318 - metrics_nse: 0.8721\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1384 - metrics_nse: 0.8647\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1263 - metrics_nse: 0.8770\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1209 - metrics_nse: 0.8820\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1198 - metrics_nse: 0.8813\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1238 - metrics_nse: 0.8792\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1235 - metrics_nse: 0.8783\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1169 - metrics_nse: 0.8855\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1190 - metrics_nse: 0.8836\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1159 - metrics_nse: 0.8867\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1134 - metrics_nse: 0.8887\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1127 - metrics_nse: 0.8893\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1113 - metrics_nse: 0.8892\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1119 - metrics_nse: 0.8902\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1078 - metrics_nse: 0.8942\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1059 - metrics_nse: 0.8968\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1016 - metrics_nse: 0.9007\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1031 - metrics_nse: 0.8980\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0982 - metrics_nse: 0.9030\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.0975 - metrics_nse: 0.9042\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.0958 - metrics_nse: 0.9058\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0963 - metrics_nse: 0.9050\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0965 - metrics_nse: 0.9046\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1002 - metrics_nse: 0.9012\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.0932 - metrics_nse: 0.9066\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0882 - metrics_nse: 0.9140\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.0888 - metrics_nse: 0.9129\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.9392393]\n",
            "Validation NSE = [0.6952888]\n",
            "--------Loading Data...........................................................\n",
            "91 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_246\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_486 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_486 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_487 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_487 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_243 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12092000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 48ms/step - loss: 1.0038 - metrics_nse: -0.0318\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.8389 - metrics_nse: 0.1352\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7662 - metrics_nse: 0.2137\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7092 - metrics_nse: 0.2722\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6753 - metrics_nse: 0.3049\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6563 - metrics_nse: 0.3267\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6343 - metrics_nse: 0.3422\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6203 - metrics_nse: 0.3566\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6133 - metrics_nse: 0.3682\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5933 - metrics_nse: 0.3877\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5852 - metrics_nse: 0.3906\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5760 - metrics_nse: 0.4051\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5584 - metrics_nse: 0.4281\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5513 - metrics_nse: 0.4284\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5428 - metrics_nse: 0.4435\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5262 - metrics_nse: 0.4606\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5280 - metrics_nse: 0.4566\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5038 - metrics_nse: 0.4759\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5121 - metrics_nse: 0.4736\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4972 - metrics_nse: 0.4890\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4984 - metrics_nse: 0.4828\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4852 - metrics_nse: 0.5034\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4753 - metrics_nse: 0.5181\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4827 - metrics_nse: 0.4987\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4788 - metrics_nse: 0.4987\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4720 - metrics_nse: 0.5129\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4725 - metrics_nse: 0.5073\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4596 - metrics_nse: 0.5222\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4618 - metrics_nse: 0.5285\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4506 - metrics_nse: 0.5307\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4477 - metrics_nse: 0.5379\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4598 - metrics_nse: 0.5239\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4514 - metrics_nse: 0.5394\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4493 - metrics_nse: 0.5442\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4445 - metrics_nse: 0.5443\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4308 - metrics_nse: 0.5558\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4351 - metrics_nse: 0.5520\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4339 - metrics_nse: 0.5558\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4245 - metrics_nse: 0.5600\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4283 - metrics_nse: 0.5620\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4388 - metrics_nse: 0.5489\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4269 - metrics_nse: 0.5579\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4290 - metrics_nse: 0.5667\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4181 - metrics_nse: 0.5667\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4198 - metrics_nse: 0.5599\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4133 - metrics_nse: 0.5722\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4142 - metrics_nse: 0.5722\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4211 - metrics_nse: 0.5632\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4100 - metrics_nse: 0.5737\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.4125 - metrics_nse: 0.5670\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.595312]\n",
            "Validation NSE = [0.5150242]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_247\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_488 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_488 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_489 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_489 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_244 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12488500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 52ms/step - loss: 0.8982 - metrics_nse: 0.0853\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7557 - metrics_nse: 0.2285\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6700 - metrics_nse: 0.3205\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6143 - metrics_nse: 0.3757\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5591 - metrics_nse: 0.4330\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.5103 - metrics_nse: 0.4831\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4713 - metrics_nse: 0.5190\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4268 - metrics_nse: 0.5669\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4035 - metrics_nse: 0.5883\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3749 - metrics_nse: 0.6154\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3555 - metrics_nse: 0.6376\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3340 - metrics_nse: 0.6599\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3262 - metrics_nse: 0.6647\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3085 - metrics_nse: 0.6865\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2914 - metrics_nse: 0.7017\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2752 - metrics_nse: 0.7179\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2680 - metrics_nse: 0.7273\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2539 - metrics_nse: 0.7419\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2466 - metrics_nse: 0.7486\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2376 - metrics_nse: 0.7587\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2293 - metrics_nse: 0.7661\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2269 - metrics_nse: 0.7686\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2181 - metrics_nse: 0.7783\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2087 - metrics_nse: 0.7864\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1977 - metrics_nse: 0.7974\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1937 - metrics_nse: 0.8030\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1848 - metrics_nse: 0.8114\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1793 - metrics_nse: 0.8166\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1688 - metrics_nse: 0.8281\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1708 - metrics_nse: 0.8256\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1613 - metrics_nse: 0.8342\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1518 - metrics_nse: 0.8452\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1509 - metrics_nse: 0.8448\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1423 - metrics_nse: 0.8546\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1349 - metrics_nse: 0.8621\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1270 - metrics_nse: 0.8709\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1303 - metrics_nse: 0.8658\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1198 - metrics_nse: 0.8780\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1196 - metrics_nse: 0.8777\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1145 - metrics_nse: 0.8826\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1112 - metrics_nse: 0.8861\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1111 - metrics_nse: 0.8868\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1094 - metrics_nse: 0.8879\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1074 - metrics_nse: 0.8905\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1077 - metrics_nse: 0.8890\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1071 - metrics_nse: 0.8895\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1051 - metrics_nse: 0.8922\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1042 - metrics_nse: 0.8941\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1024 - metrics_nse: 0.8952\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1009 - metrics_nse: 0.8972\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.9229976]\n",
            "Validation NSE = [0.6975524]\n",
            "--------Loading Data...........................................................\n",
            "28 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_248\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_490 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_490 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_491 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_491 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_245 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12189500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 51ms/step - loss: 0.8632 - metrics_nse: 0.0969\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7487 - metrics_nse: 0.2238\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6664 - metrics_nse: 0.3125\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6089 - metrics_nse: 0.3715\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5561 - metrics_nse: 0.4258\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5208 - metrics_nse: 0.4638\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4819 - metrics_nse: 0.5118\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4599 - metrics_nse: 0.5335\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4501 - metrics_nse: 0.5433\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4352 - metrics_nse: 0.5535\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4233 - metrics_nse: 0.5665\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4140 - metrics_nse: 0.5715\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4025 - metrics_nse: 0.6007\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3960 - metrics_nse: 0.5960\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3840 - metrics_nse: 0.6061\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3797 - metrics_nse: 0.6235\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3762 - metrics_nse: 0.6163\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3714 - metrics_nse: 0.6191\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3680 - metrics_nse: 0.6277\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3628 - metrics_nse: 0.6339\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3591 - metrics_nse: 0.6253\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3427 - metrics_nse: 0.6437\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3485 - metrics_nse: 0.6407\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3446 - metrics_nse: 0.6552\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3410 - metrics_nse: 0.6539\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3417 - metrics_nse: 0.6586\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3349 - metrics_nse: 0.6590\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3175 - metrics_nse: 0.6741\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3259 - metrics_nse: 0.6751\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3215 - metrics_nse: 0.6732\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3235 - metrics_nse: 0.6719\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3165 - metrics_nse: 0.6826\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3214 - metrics_nse: 0.6728\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3196 - metrics_nse: 0.6704\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3009 - metrics_nse: 0.7011\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3142 - metrics_nse: 0.6850\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3050 - metrics_nse: 0.7018\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3023 - metrics_nse: 0.6989\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3015 - metrics_nse: 0.6923\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2995 - metrics_nse: 0.6988\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2957 - metrics_nse: 0.7002\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2923 - metrics_nse: 0.7024\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2870 - metrics_nse: 0.7094\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2868 - metrics_nse: 0.7109\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2907 - metrics_nse: 0.7114\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2899 - metrics_nse: 0.7039\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2885 - metrics_nse: 0.7146\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2800 - metrics_nse: 0.7130\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2749 - metrics_nse: 0.7257\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2824 - metrics_nse: 0.7141\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.7370436]\n",
            "Validation NSE = [0.6340056]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_249\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_492 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_492 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_493 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_493 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_246 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12167000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 51ms/step - loss: 0.8226 - metrics_nse: 0.1576\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.7172 - metrics_nse: 0.2699\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6551 - metrics_nse: 0.3309\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6166 - metrics_nse: 0.3726\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5912 - metrics_nse: 0.3949\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5743 - metrics_nse: 0.4117\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5631 - metrics_nse: 0.4309\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5425 - metrics_nse: 0.4475\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.5517 - metrics_nse: 0.4416\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5312 - metrics_nse: 0.4582\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5252 - metrics_nse: 0.4676\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5133 - metrics_nse: 0.4785\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5070 - metrics_nse: 0.4952\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5023 - metrics_nse: 0.4892\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4978 - metrics_nse: 0.4986\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4837 - metrics_nse: 0.5110\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4850 - metrics_nse: 0.5066\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4893 - metrics_nse: 0.5025\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4842 - metrics_nse: 0.5124\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4810 - metrics_nse: 0.5162\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4732 - metrics_nse: 0.5149\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4707 - metrics_nse: 0.5152\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4726 - metrics_nse: 0.5143\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4747 - metrics_nse: 0.5208\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4549 - metrics_nse: 0.5373\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4517 - metrics_nse: 0.5436\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4664 - metrics_nse: 0.5254\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4563 - metrics_nse: 0.5338\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4600 - metrics_nse: 0.5355\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4486 - metrics_nse: 0.5449\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4528 - metrics_nse: 0.5583\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4533 - metrics_nse: 0.5382\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4462 - metrics_nse: 0.5554\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4481 - metrics_nse: 0.5409\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4434 - metrics_nse: 0.5371\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4433 - metrics_nse: 0.5603\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4396 - metrics_nse: 0.5502\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4461 - metrics_nse: 0.5472\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4444 - metrics_nse: 0.5609\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4358 - metrics_nse: 0.5597\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4353 - metrics_nse: 0.5522\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4395 - metrics_nse: 0.5463\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4343 - metrics_nse: 0.5691\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.4320 - metrics_nse: 0.5614\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4331 - metrics_nse: 0.5523\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4252 - metrics_nse: 0.5616\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4265 - metrics_nse: 0.5688\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4238 - metrics_nse: 0.5632\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4266 - metrics_nse: 0.5730\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4270 - metrics_nse: 0.5682\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.587976]\n",
            "Validation NSE = [0.56883305]\n",
            "--------Loading Data...........................................................\n",
            "24 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_250\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_494 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_494 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_495 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_495 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_247 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 13161500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 49ms/step - loss: 0.7989 - metrics_nse: 0.2417\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7018 - metrics_nse: 0.3373\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6500 - metrics_nse: 0.3877\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6299 - metrics_nse: 0.4052\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.6143 - metrics_nse: 0.4214\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5810 - metrics_nse: 0.4535\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5608 - metrics_nse: 0.4724\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5246 - metrics_nse: 0.5065\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4946 - metrics_nse: 0.5378\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4691 - metrics_nse: 0.5595\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4466 - metrics_nse: 0.5781\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4285 - metrics_nse: 0.5977\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3897 - metrics_nse: 0.6305\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3720 - metrics_nse: 0.6500\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3467 - metrics_nse: 0.6706\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3319 - metrics_nse: 0.6866\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3021 - metrics_nse: 0.7162\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2922 - metrics_nse: 0.7228\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2844 - metrics_nse: 0.7322\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2685 - metrics_nse: 0.7462\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2546 - metrics_nse: 0.7600\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2479 - metrics_nse: 0.7655\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2360 - metrics_nse: 0.7782\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2303 - metrics_nse: 0.7832\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2286 - metrics_nse: 0.7839\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2278 - metrics_nse: 0.7844\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2433 - metrics_nse: 0.7676\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2311 - metrics_nse: 0.7837\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2283 - metrics_nse: 0.7815\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2158 - metrics_nse: 0.7943\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2101 - metrics_nse: 0.8002\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2110 - metrics_nse: 0.8003\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.2097 - metrics_nse: 0.8015\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2134 - metrics_nse: 0.7988\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1996 - metrics_nse: 0.8128\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2007 - metrics_nse: 0.8118\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1946 - metrics_nse: 0.8155\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2028 - metrics_nse: 0.8091\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1984 - metrics_nse: 0.8139\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1946 - metrics_nse: 0.8167\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1891 - metrics_nse: 0.8232\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1808 - metrics_nse: 0.8303\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.1904 - metrics_nse: 0.8179\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1798 - metrics_nse: 0.8291\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1845 - metrics_nse: 0.8263\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1752 - metrics_nse: 0.8330\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1753 - metrics_nse: 0.8356\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1820 - metrics_nse: 0.8265\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1759 - metrics_nse: 0.8342\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1721 - metrics_nse: 0.8374\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.85585165]\n",
            "Validation NSE = [0.45354098]\n",
            "--------Loading Data...........................................................\n",
            "2557 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_251\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_496 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_496 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_497 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_497 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_248 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12388400 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 50ms/step - loss: 1.1097 - metrics_nse: -0.1033\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.8055 - metrics_nse: 0.2132\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.7630 - metrics_nse: 0.2510\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.7352 - metrics_nse: 0.2838\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.7047 - metrics_nse: 0.3138\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6848 - metrics_nse: 0.3310\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6632 - metrics_nse: 0.3546\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6356 - metrics_nse: 0.3796\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6088 - metrics_nse: 0.4062\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5759 - metrics_nse: 0.4375\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.5476 - metrics_nse: 0.4630\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.5265 - metrics_nse: 0.4842\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5164 - metrics_nse: 0.4972\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5017 - metrics_nse: 0.5116\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4984 - metrics_nse: 0.5110\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4929 - metrics_nse: 0.5199\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4883 - metrics_nse: 0.5239\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4861 - metrics_nse: 0.5260\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4859 - metrics_nse: 0.5215\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4802 - metrics_nse: 0.5319\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4657 - metrics_nse: 0.5463\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4589 - metrics_nse: 0.5496\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4630 - metrics_nse: 0.5434\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4576 - metrics_nse: 0.5522\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4503 - metrics_nse: 0.5543\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4504 - metrics_nse: 0.5617\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4355 - metrics_nse: 0.5744\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4449 - metrics_nse: 0.5581\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4361 - metrics_nse: 0.5761\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4227 - metrics_nse: 0.5824\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4178 - metrics_nse: 0.5938\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4249 - metrics_nse: 0.5853\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4124 - metrics_nse: 0.5950\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4025 - metrics_nse: 0.6067\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4036 - metrics_nse: 0.6068\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3893 - metrics_nse: 0.6216\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3731 - metrics_nse: 0.6387\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3666 - metrics_nse: 0.6427\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3545 - metrics_nse: 0.6522\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3346 - metrics_nse: 0.6744\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.3190 - metrics_nse: 0.6826\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3240 - metrics_nse: 0.6811\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3163 - metrics_nse: 0.6820\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3065 - metrics_nse: 0.7013\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3040 - metrics_nse: 0.7009\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2889 - metrics_nse: 0.7140\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2987 - metrics_nse: 0.7069\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2952 - metrics_nse: 0.7040\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2905 - metrics_nse: 0.7114\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2798 - metrics_nse: 0.7244\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.70177567]\n",
            "Validation NSE = [-0.05515659]\n",
            "--------Loading Data...........................................................\n",
            "1247 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_252\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_498 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_498 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_499 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_499 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_249 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12043000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 3s 54ms/step - loss: 0.8463 - metrics_nse: 0.2005\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.7256 - metrics_nse: 0.3150\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.6568 - metrics_nse: 0.3774\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.6126 - metrics_nse: 0.4369\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.5876 - metrics_nse: 0.4547\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.5576 - metrics_nse: 0.4858\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.5422 - metrics_nse: 0.4901\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.5281 - metrics_nse: 0.5049\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.5102 - metrics_nse: 0.5241\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5090 - metrics_nse: 0.5418\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.4884 - metrics_nse: 0.5377\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4881 - metrics_nse: 0.5360\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.4700 - metrics_nse: 0.5740\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4663 - metrics_nse: 0.5567\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4663 - metrics_nse: 0.5629\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4499 - metrics_nse: 0.5814\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4503 - metrics_nse: 0.5842\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4453 - metrics_nse: 0.5929\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4452 - metrics_nse: 0.5922\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.4413 - metrics_nse: 0.5781\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4352 - metrics_nse: 0.5969\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4427 - metrics_nse: 0.5928\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.4288 - metrics_nse: 0.5931\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4329 - metrics_nse: 0.5956\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.4189 - metrics_nse: 0.6081\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.4258 - metrics_nse: 0.5924\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4087 - metrics_nse: 0.6112\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.4280 - metrics_nse: 0.5966\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.4158 - metrics_nse: 0.6032\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.4237 - metrics_nse: 0.6039\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4146 - metrics_nse: 0.6134\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4066 - metrics_nse: 0.6199\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4164 - metrics_nse: 0.5969\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4093 - metrics_nse: 0.6318\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.4089 - metrics_nse: 0.6174\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.4083 - metrics_nse: 0.6217\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.4031 - metrics_nse: 0.6227\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.4002 - metrics_nse: 0.6396\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.4051 - metrics_nse: 0.6178\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 0.3997 - metrics_nse: 0.6256\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.4022 - metrics_nse: 0.6261\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.3980 - metrics_nse: 0.6277\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.4012 - metrics_nse: 0.6270\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.4075 - metrics_nse: 0.6232\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.3905 - metrics_nse: 0.6302\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.3904 - metrics_nse: 0.6410\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.3887 - metrics_nse: 0.6238\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.3928 - metrics_nse: 0.6252\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3947 - metrics_nse: 0.6347\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 47ms/step - loss: 0.3856 - metrics_nse: 0.6430\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.64692545]\n",
            "Validation NSE = [0.5932067]\n",
            "--------Loading Data...........................................................\n",
            "82 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_253\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_500 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_500 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_501 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_501 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_250 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12451000 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 50ms/step - loss: 0.9270 - metrics_nse: 0.0955\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6777 - metrics_nse: 0.3331\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.6309 - metrics_nse: 0.3814\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 44ms/step - loss: 0.5697 - metrics_nse: 0.4412\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5314 - metrics_nse: 0.4786\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5036 - metrics_nse: 0.5036\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4724 - metrics_nse: 0.5385\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4439 - metrics_nse: 0.5656\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4063 - metrics_nse: 0.6025\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3756 - metrics_nse: 0.6352\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3537 - metrics_nse: 0.6526\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3344 - metrics_nse: 0.6732\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3210 - metrics_nse: 0.6851\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3073 - metrics_nse: 0.6982\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2988 - metrics_nse: 0.7094\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2850 - metrics_nse: 0.7209\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2688 - metrics_nse: 0.7371\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2592 - metrics_nse: 0.7452\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2544 - metrics_nse: 0.7530\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2496 - metrics_nse: 0.7540\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2380 - metrics_nse: 0.7630\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2327 - metrics_nse: 0.7756\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2209 - metrics_nse: 0.7823\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2135 - metrics_nse: 0.7915\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2081 - metrics_nse: 0.7958\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2040 - metrics_nse: 0.7998\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2004 - metrics_nse: 0.8052\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1959 - metrics_nse: 0.8098\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1878 - metrics_nse: 0.8170\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1927 - metrics_nse: 0.8119\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1849 - metrics_nse: 0.8181\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1801 - metrics_nse: 0.8226\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1748 - metrics_nse: 0.8311\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1748 - metrics_nse: 0.8301\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1721 - metrics_nse: 0.8330\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1672 - metrics_nse: 0.8349\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1689 - metrics_nse: 0.8350\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1650 - metrics_nse: 0.8376\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1670 - metrics_nse: 0.8380\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1571 - metrics_nse: 0.8455\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.1608 - metrics_nse: 0.8430\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.1569 - metrics_nse: 0.8472\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1537 - metrics_nse: 0.8515\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.1515 - metrics_nse: 0.8507\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1521 - metrics_nse: 0.8512\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1498 - metrics_nse: 0.8542\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1446 - metrics_nse: 0.8574\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1428 - metrics_nse: 0.8619\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.1402 - metrics_nse: 0.8639\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.1451 - metrics_nse: 0.8585\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.8832035]\n",
            "Validation NSE = [0.77249634]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_254\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_502 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_502 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_503 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_503 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_251 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12145500 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 52ms/step - loss: 0.8240 - metrics_nse: 0.2005\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6875 - metrics_nse: 0.3395\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.6086 - metrics_nse: 0.4160\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5601 - metrics_nse: 0.4708\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5312 - metrics_nse: 0.5052\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5155 - metrics_nse: 0.5285\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4960 - metrics_nse: 0.5264\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4859 - metrics_nse: 0.5368\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4778 - metrics_nse: 0.5526\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4564 - metrics_nse: 0.5599\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4547 - metrics_nse: 0.5675\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4520 - metrics_nse: 0.5700\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4317 - metrics_nse: 0.5973\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4315 - metrics_nse: 0.5995\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4271 - metrics_nse: 0.5987\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4274 - metrics_nse: 0.5984\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4105 - metrics_nse: 0.6067\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4076 - metrics_nse: 0.6246\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.4106 - metrics_nse: 0.6229\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4021 - metrics_nse: 0.6258\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4054 - metrics_nse: 0.6145\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3977 - metrics_nse: 0.6300\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3895 - metrics_nse: 0.6286\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3801 - metrics_nse: 0.6364\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3876 - metrics_nse: 0.6303\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3931 - metrics_nse: 0.6251\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3677 - metrics_nse: 0.6551\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3830 - metrics_nse: 0.6318\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3674 - metrics_nse: 0.6587\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3599 - metrics_nse: 0.6579\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3707 - metrics_nse: 0.6450\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3612 - metrics_nse: 0.6533\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3573 - metrics_nse: 0.6538\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3598 - metrics_nse: 0.6608\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3522 - metrics_nse: 0.6675\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3556 - metrics_nse: 0.6648\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3534 - metrics_nse: 0.6604\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3441 - metrics_nse: 0.6774\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3578 - metrics_nse: 0.6706\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3572 - metrics_nse: 0.6527\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.3432 - metrics_nse: 0.6802\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3291 - metrics_nse: 0.6796\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3407 - metrics_nse: 0.6709\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3370 - metrics_nse: 0.6828\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3373 - metrics_nse: 0.6840\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3304 - metrics_nse: 0.6828\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3253 - metrics_nse: 0.6925\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3433 - metrics_nse: 0.6729\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3319 - metrics_nse: 0.6885\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3353 - metrics_nse: 0.6882\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.6980535]\n",
            "Validation NSE = [0.6979743]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_255\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_504 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_504 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_505 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_505 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_252 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 14158790 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 50ms/step - loss: 0.7898 - metrics_nse: 0.1912\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6995 - metrics_nse: 0.2866\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.6231 - metrics_nse: 0.3606\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5818 - metrics_nse: 0.4041\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.5501 - metrics_nse: 0.4380\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5169 - metrics_nse: 0.4661\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.5063 - metrics_nse: 0.4818\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4783 - metrics_nse: 0.5100\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.4634 - metrics_nse: 0.5222\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4494 - metrics_nse: 0.5398\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.4319 - metrics_nse: 0.5556\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4006 - metrics_nse: 0.5895\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3928 - metrics_nse: 0.5949\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3653 - metrics_nse: 0.6189\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3625 - metrics_nse: 0.6298\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3545 - metrics_nse: 0.6376\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3396 - metrics_nse: 0.6536\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3287 - metrics_nse: 0.6636\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3252 - metrics_nse: 0.6696\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3055 - metrics_nse: 0.6898\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3061 - metrics_nse: 0.6875\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 1s 50ms/step - loss: 0.2997 - metrics_nse: 0.6944\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2938 - metrics_nse: 0.7000\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2917 - metrics_nse: 0.6967\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2843 - metrics_nse: 0.7078\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2807 - metrics_nse: 0.7114\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2756 - metrics_nse: 0.7179\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2681 - metrics_nse: 0.7243\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2653 - metrics_nse: 0.7254\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.2685 - metrics_nse: 0.7227\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2639 - metrics_nse: 0.7291\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2563 - metrics_nse: 0.7359\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2532 - metrics_nse: 0.7401\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2493 - metrics_nse: 0.7438\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2458 - metrics_nse: 0.7525\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.2478 - metrics_nse: 0.7477\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2382 - metrics_nse: 0.7568\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2469 - metrics_nse: 0.7440\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2377 - metrics_nse: 0.7539\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2311 - metrics_nse: 0.7658\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2323 - metrics_nse: 0.7624\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2338 - metrics_nse: 0.7634\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2205 - metrics_nse: 0.7756\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2296 - metrics_nse: 0.7640\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.2273 - metrics_nse: 0.7653\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2205 - metrics_nse: 0.7719\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 1s 51ms/step - loss: 0.2184 - metrics_nse: 0.7741\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2265 - metrics_nse: 0.7684\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2235 - metrics_nse: 0.7687\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.2182 - metrics_nse: 0.7777\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.8115986]\n",
            "Validation NSE = [0.6578665]\n",
            "--------Loading Data...........................................................\n",
            "0 SAMPLES WHERE DELETED DUE TO MISSING DATA\n",
            "--------Data-loading complete--------------------------------------------------\n",
            "--------Creating Training and Test samples.....................................\n",
            "--------Standardizing data.....................................................\n",
            "--------Shaping sequences......................................................\n",
            "Model: \"sequential_256\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_506 (GRU)               (None, 365, 20)           1620      \n",
            "                                                                 \n",
            " dropout_506 (Dropout)       (None, 365, 20)           0         \n",
            "                                                                 \n",
            " gru_507 (GRU)               (None, 20)                2520      \n",
            "                                                                 \n",
            " dropout_507 (Dropout)       (None, 20)                0         \n",
            "                                                                 \n",
            " dense_253 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,161\n",
            "Trainable params: 4,161\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------START TRAINING OF CATCHMENT 12025700 in HUC 17--------\n",
            "--------Training period: 1981/10/01 - 1995/09/30------------------------------\n",
            "Epoch 1/50\n",
            "10/10 [==============================] - 3s 48ms/step - loss: 0.7842 - metrics_nse: 0.2248\n",
            "Epoch 2/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.6549 - metrics_nse: 0.3551\n",
            "Epoch 3/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5660 - metrics_nse: 0.4484\n",
            "Epoch 4/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.5181 - metrics_nse: 0.4993\n",
            "Epoch 5/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4885 - metrics_nse: 0.5301\n",
            "Epoch 6/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4570 - metrics_nse: 0.5588\n",
            "Epoch 7/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4385 - metrics_nse: 0.5752\n",
            "Epoch 8/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.4207 - metrics_nse: 0.5947\n",
            "Epoch 9/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.4104 - metrics_nse: 0.6006\n",
            "Epoch 10/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3989 - metrics_nse: 0.6121\n",
            "Epoch 11/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3962 - metrics_nse: 0.6179\n",
            "Epoch 12/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3895 - metrics_nse: 0.6117\n",
            "Epoch 13/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3736 - metrics_nse: 0.6398\n",
            "Epoch 14/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3647 - metrics_nse: 0.6419\n",
            "Epoch 15/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3540 - metrics_nse: 0.6606\n",
            "Epoch 16/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3584 - metrics_nse: 0.6542\n",
            "Epoch 17/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3536 - metrics_nse: 0.6584\n",
            "Epoch 18/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3508 - metrics_nse: 0.6634\n",
            "Epoch 19/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3502 - metrics_nse: 0.6592\n",
            "Epoch 20/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3395 - metrics_nse: 0.6684\n",
            "Epoch 21/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3391 - metrics_nse: 0.6771\n",
            "Epoch 22/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3299 - metrics_nse: 0.6906\n",
            "Epoch 23/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3275 - metrics_nse: 0.6800\n",
            "Epoch 24/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3366 - metrics_nse: 0.6741\n",
            "Epoch 25/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3296 - metrics_nse: 0.6743\n",
            "Epoch 26/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3206 - metrics_nse: 0.6857\n",
            "Epoch 27/50\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3243 - metrics_nse: 0.6838\n",
            "Epoch 28/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3257 - metrics_nse: 0.6849\n",
            "Epoch 29/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3196 - metrics_nse: 0.6938\n",
            "Epoch 30/50\n",
            "10/10 [==============================] - 0s 51ms/step - loss: 0.3219 - metrics_nse: 0.6859\n",
            "Epoch 31/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3192 - metrics_nse: 0.6911\n",
            "Epoch 32/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3128 - metrics_nse: 0.7001\n",
            "Epoch 33/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3198 - metrics_nse: 0.7034\n",
            "Epoch 34/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3115 - metrics_nse: 0.7051\n",
            "Epoch 35/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3145 - metrics_nse: 0.7022\n",
            "Epoch 36/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3154 - metrics_nse: 0.7005\n",
            "Epoch 37/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3108 - metrics_nse: 0.7028\n",
            "Epoch 38/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3071 - metrics_nse: 0.7065\n",
            "Epoch 39/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3070 - metrics_nse: 0.7076\n",
            "Epoch 40/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3053 - metrics_nse: 0.6986\n",
            "Epoch 41/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2965 - metrics_nse: 0.7174\n",
            "Epoch 42/50\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.3040 - metrics_nse: 0.7065\n",
            "Epoch 43/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3083 - metrics_nse: 0.6990\n",
            "Epoch 44/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3046 - metrics_nse: 0.7031\n",
            "Epoch 45/50\n",
            "10/10 [==============================] - 0s 45ms/step - loss: 0.3035 - metrics_nse: 0.7129\n",
            "Epoch 46/50\n",
            "10/10 [==============================] - 0s 46ms/step - loss: 0.3036 - metrics_nse: 0.7036\n",
            "Epoch 47/50\n",
            "10/10 [==============================] - 0s 47ms/step - loss: 0.3008 - metrics_nse: 0.7069\n",
            "Epoch 48/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2940 - metrics_nse: 0.7127\n",
            "Epoch 49/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.2971 - metrics_nse: 0.7071\n",
            "Epoch 50/50\n",
            "10/10 [==============================] - 0s 48ms/step - loss: 0.3001 - metrics_nse: 0.7123\n",
            "--------End of Training-------------------------------------------------------\n",
            "--------Start of Evaluation---------------------------------------------------\n",
            "--------Evaluation period 1996/10/01-2010/09/30-------------------------------\n",
            "Training NSE =  [0.7210677]\n",
            "Validation NSE = [0.6407193]\n",
            "   catchment_ID     nse_train       nse_val\n",
            "0      12073500  [0.64432335]   [0.5400667]\n",
            "1      14185000  [0.80422187]   [0.7324066]\n",
            "2      13340600  [0.93975526]   [0.8298965]\n",
            "3      13338500   [0.9306776]   [0.7857882]\n",
            "4      14222500  [0.76848304]   [0.7439914]\n",
            "..          ...           ...           ...\n",
            "86     12043000  [0.64692545]   [0.5932067]\n",
            "87     12451000   [0.8832035]  [0.77249634]\n",
            "88     12145500   [0.6980535]   [0.6979743]\n",
            "89     14158790   [0.8115986]   [0.6578665]\n",
            "90     12025700   [0.7210677]   [0.6407193]\n",
            "\n",
            "[91 rows x 3 columns]\n"
          ]
        }
      ]
    }
  ]
}